* 
* ==> Audit <==
* |---------|-----------------|----------|-------|---------|---------------------|---------------------|
| Command |      Args       | Profile  | User  | Version |     Start Time      |      End Time       |
|---------|-----------------|----------|-------|---------|---------------------|---------------------|
| start   |                 | minikube | teddy | v1.28.0 | 19 Jan 23 04:04 JST | 19 Jan 23 04:12 JST |
| start   |                 | minikube | teddy | v1.28.0 | 19 Jan 23 04:16 JST | 19 Jan 23 04:18 JST |
| stop    |                 | minikube | teddy | v1.28.0 | 19 Jan 23 04:21 JST | 19 Jan 23 04:21 JST |
| start   |                 | minikube | teddy | v1.28.0 | 20 Jan 23 03:53 JST | 20 Jan 23 03:55 JST |
| stop    |                 | minikube | teddy | v1.28.0 | 20 Jan 23 05:26 JST | 20 Jan 23 05:26 JST |
| start   |                 | minikube | teddy | v1.28.0 | 22 Jan 23 04:13 JST | 22 Jan 23 04:15 JST |
| service | posts-srv       | minikube | teddy | v1.28.0 | 22 Jan 23 04:26 JST | 22 Jan 23 04:37 JST |
| ip      |                 | minikube | teddy | v1.28.0 | 22 Jan 23 04:40 JST | 22 Jan 23 04:40 JST |
| ip      |                 | minikube | teddy | v1.28.0 | 22 Jan 23 05:20 JST | 22 Jan 23 05:20 JST |
| service | posts-srv       | minikube | teddy | v1.28.0 | 22 Jan 23 05:44 JST | 22 Jan 23 05:48 JST |
| service | posts-srv       | minikube | teddy | v1.28.0 | 22 Jan 23 05:45 JST | 22 Jan 23 05:48 JST |
| service | posts-srv       | minikube | teddy | v1.28.0 | 22 Jan 23 05:49 JST |                     |
| service | posts-srv       | minikube | teddy | v1.28.0 | 22 Jan 23 05:51 JST | 22 Jan 23 05:51 JST |
| service | posts-srv --url | minikube | teddy | v1.28.0 | 22 Jan 23 05:53 JST | 22 Jan 23 06:03 JST |
| service | posts-srv       | minikube | teddy | v1.28.0 | 22 Jan 23 06:04 JST | 22 Jan 23 06:05 JST |
| service | posts-srv --url | minikube | teddy | v1.28.0 | 22 Jan 23 06:05 JST | 22 Jan 23 06:05 JST |
| service | posts-srv --url | minikube | teddy | v1.28.0 | 22 Jan 23 06:13 JST | 22 Jan 23 06:22 JST |
| service | posts-srv --url | minikube | teddy | v1.28.0 | 22 Jan 23 06:42 JST | 22 Jan 23 06:43 JST |
| service | posts-srv --url | minikube | teddy | v1.28.0 | 22 Jan 23 06:46 JST | 22 Jan 23 07:25 JST |
| stop    |                 | minikube | teddy | v1.28.0 | 22 Jan 23 07:22 JST | 22 Jan 23 07:23 JST |
| start   |                 | minikube | teddy | v1.28.0 | 23 Jan 23 02:27 JST | 23 Jan 23 02:29 JST |
| service | posts-srv --url | minikube | teddy | v1.28.0 | 23 Jan 23 03:23 JST | 23 Jan 23 03:29 JST |
| stop    |                 | minikube | teddy | v1.28.0 | 23 Jan 23 03:29 JST | 23 Jan 23 03:29 JST |
| start   |                 | minikube | teddy | v1.28.0 | 25 Jan 23 01:29 JST | 25 Jan 23 01:31 JST |
| addons  | enable ingress  | minikube | teddy | v1.28.0 | 25 Jan 23 01:39 JST |                     |
|---------|-----------------|----------|-------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/01/25 01:29:56
Running on machine: perfect„ÇÜ„Å£„Åè„Çä
Binary: Built with gc go1.19.2 for linux/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0125 01:29:56.170634     903 out.go:296] Setting OutFile to fd 1 ...
I0125 01:29:56.170824     903 out.go:348] isatty.IsTerminal(1) = true
I0125 01:29:56.170828     903 out.go:309] Setting ErrFile to fd 2...
I0125 01:29:56.170833     903 out.go:348] isatty.IsTerminal(2) = true
I0125 01:29:56.170943     903 root.go:334] Updating PATH: /home/teddy/.minikube/bin
W0125 01:29:56.204156     903 root.go:311] Error reading config file at /home/teddy/.minikube/config/config.json: open /home/teddy/.minikube/config/config.json: no such file or directory
I0125 01:29:56.228133     903 out.go:303] Setting JSON to false
I0125 01:29:56.564603     903 start.go:116] hostinfo: {"hostname":"perfect„ÇÜ„Å£„Åè„Çä","uptime":3692,"bootTime":1674574104,"procs":24,"os":"linux","platform":"ubuntu","platformFamily":"debian","platformVersion":"20.04","kernelVersion":"4.19.128-microsoft-standard","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"4e0310b4-82df-e904-6aed-20f562e18a80"}
I0125 01:29:56.564670     903 start.go:126] virtualization:  
I0125 01:29:56.686033     903 out.go:177] üòÑ  minikube v1.28.0 on Ubuntu 20.04
I0125 01:29:56.774774     903 notify.go:220] Checking for updates...
I0125 01:29:56.817864     903 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0125 01:29:56.938751     903 driver.go:365] Setting default libvirt URI to qemu:///system
I0125 01:29:58.950288     903 docker.go:137] docker version: linux-20.10.17
I0125 01:29:58.950377     903 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0125 01:30:02.039392     903 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (3.0889889s)
I0125 01:30:02.039819     903 info.go:266] docker info: {ID:JW7X:K2QP:S57A:JAPA:E65C:VRHY:5O62:Z35H:6F62:TV4Q:XV4U:7SIV Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:34 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:39 SystemTime:2023-01-25 01:29:59.0206353 +0900 JST LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:4.19.128-microsoft-standard OperatingSystem:Ubuntu 20.04.4 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:3135004672 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:perfect„ÇÜ„Å£„Åè„Çä Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb Expected:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb} RuncCommit:{ID:v1.1.3-0-g6724737 Expected:v1.1.3-0-g6724737} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Experimental:true Name:app Path:/usr/libexec/docker/cli-plugins/docker-app SchemaVersion:0.1.0 ShortDescription:Docker App Vendor:Docker Inc. Version:v0.9.1-beta3] map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2-docker] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:scan Path:/usr/libexec/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0125 01:30:02.040110     903 docker.go:254] overlay module found
I0125 01:30:02.251084     903 out.go:177] ‚ú®  Using the docker driver based on existing profile
I0125 01:30:02.379502     903 start.go:282] selected driver: docker
I0125 01:30:02.379533     903 start.go:808] validating driver "docker" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/teddy:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0125 01:30:02.379635     903 start.go:819] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0125 01:30:02.379728     903 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0125 01:30:02.505903     903 info.go:266] docker info: {ID:JW7X:K2QP:S57A:JAPA:E65C:VRHY:5O62:Z35H:6F62:TV4Q:XV4U:7SIV Containers:2 ContainersRunning:0 ContainersPaused:0 ContainersStopped:2 Images:34 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:24 OomKillDisable:true NGoroutines:39 SystemTime:2023-01-25 01:30:02.4152952 +0900 JST LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:0 KernelVersion:4.19.128-microsoft-standard OperatingSystem:Ubuntu 20.04.4 LTS OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:3135004672 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy: HTTPSProxy: NoProxy: Name:perfect„ÇÜ„Å£„Åè„Çä Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb Expected:0197261a30bf81f1ee8e6a4dd2dea0ef95d67ccb} RuncCommit:{ID:v1.1.3-0-g6724737 Expected:v1.1.3-0-g6724737} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Experimental:true Name:app Path:/usr/libexec/docker/cli-plugins/docker-app SchemaVersion:0.1.0 ShortDescription:Docker App Vendor:Docker Inc. Version:v0.9.1-beta3] map[Name:buildx Path:/usr/libexec/docker/cli-plugins/docker-buildx SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.8.2-docker] map[Name:compose Path:/usr/libexec/docker/cli-plugins/docker-compose SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.6.0] map[Name:scan Path:/usr/libexec/docker/cli-plugins/docker-scan SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.17.0]] Warnings:<nil>}}
I0125 01:30:02.650315     903 out.go:177] 
W0125 01:30:02.713189     903 out.go:239] üßØ  The requested memory allocation of 2200MiB does not leave room for system overhead (total system memory: 2989MiB). You may face stability issues.
W0125 01:30:02.713345     903 out.go:239] üí°  Suggestion: Start minikube with less memory allocated: 'minikube start --memory=2200mb'
I0125 01:30:02.825387     903 out.go:177] 
I0125 01:30:02.913233     903 cni.go:95] Creating CNI manager for ""
I0125 01:30:02.913259     903 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0125 01:30:02.913278     903 start_flags.go:317] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/teddy:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0125 01:30:03.000370     903 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0125 01:30:03.067007     903 cache.go:120] Beginning downloading kic base image for docker with docker
I0125 01:30:03.133738     903 out.go:177] üöú  Pulling base image ...
I0125 01:30:03.200475     903 image.go:76] Checking for gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 in local docker daemon
I0125 01:30:03.200503     903 preload.go:132] Checking if preload exists for k8s version v1.25.3 and runtime docker
I0125 01:30:03.200613     903 preload.go:148] Found local preload: /home/teddy/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.25.3-docker-overlay2-amd64.tar.lz4
I0125 01:30:03.200630     903 cache.go:57] Caching tarball of preloaded images
I0125 01:30:03.224057     903 preload.go:174] Found /home/teddy/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.25.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0125 01:30:03.224091     903 cache.go:60] Finished verifying existence of preloaded tar for  v1.25.3 on docker
I0125 01:30:03.224275     903 profile.go:148] Saving config to /home/teddy/.minikube/profiles/minikube/config.json ...
I0125 01:30:03.257590     903 image.go:80] Found gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 in local docker daemon, skipping pull
I0125 01:30:03.257604     903 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 exists in daemon, skipping load
I0125 01:30:03.257637     903 cache.go:208] Successfully downloaded all kic artifacts
I0125 01:30:03.257675     903 start.go:364] acquiring machines lock for minikube: {Name:mkcd1de5eaacadd5a9b53a0df008f467729e9f40 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0125 01:30:03.263516     903 start.go:368] acquired machines lock for "minikube" in 5.8208ms
I0125 01:30:03.263535     903 start.go:96] Skipping create...Using existing machine configuration
I0125 01:30:03.263539     903 fix.go:55] fixHost starting: 
I0125 01:30:03.263781     903 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0125 01:30:03.690081     903 fix.go:103] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0125 01:30:03.690097     903 fix.go:129] unexpected machine state, will restart: <nil>
I0125 01:30:03.773116     903 out.go:177] üîÑ  Restarting existing docker container for "minikube" ...
I0125 01:30:03.917233     903 cli_runner.go:164] Run: docker start minikube
I0125 01:30:08.085720     903 cli_runner.go:217] Completed: docker start minikube: (4.1684604s)
I0125 01:30:08.085802     903 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0125 01:30:08.114808     903 kic.go:415] container "minikube" state is running.
I0125 01:30:08.115303     903 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0125 01:30:08.142940     903 profile.go:148] Saving config to /home/teddy/.minikube/profiles/minikube/config.json ...
I0125 01:30:08.143235     903 machine.go:88] provisioning docker machine ...
I0125 01:30:08.143253     903 ubuntu.go:169] provisioning hostname "minikube"
I0125 01:30:08.143304     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:08.170758     903 main.go:134] libmachine: Using SSH client type: native
I0125 01:30:08.198721     903 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7ed4e0] 0x7f0660 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0125 01:30:08.198733     903 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0125 01:30:08.199735     903 main.go:134] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:47302->127.0.0.1:49157: read: connection reset by peer
I0125 01:30:11.201224     903 main.go:134] libmachine: Error dialing TCP: ssh: handshake failed: read tcp 127.0.0.1:47306->127.0.0.1:49157: read: connection reset by peer
I0125 01:30:15.586521     903 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0125 01:30:15.586601     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:15.643591     903 main.go:134] libmachine: Using SSH client type: native
I0125 01:30:15.643716     903 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7ed4e0] 0x7f0660 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0125 01:30:15.643733     903 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0125 01:30:15.785445     903 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0125 01:30:15.785487     903 ubuntu.go:175] set auth options {CertDir:/home/teddy/.minikube CaCertPath:/home/teddy/.minikube/certs/ca.pem CaPrivateKeyPath:/home/teddy/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/teddy/.minikube/machines/server.pem ServerKeyPath:/home/teddy/.minikube/machines/server-key.pem ClientKeyPath:/home/teddy/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/teddy/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/teddy/.minikube}
I0125 01:30:15.785519     903 ubuntu.go:177] setting up certificates
I0125 01:30:15.785530     903 provision.go:83] configureAuth start
I0125 01:30:15.785612     903 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0125 01:30:15.811366     903 provision.go:138] copyHostCerts
I0125 01:30:15.858142     903 exec_runner.go:144] found /home/teddy/.minikube/ca.pem, removing ...
I0125 01:30:15.858157     903 exec_runner.go:207] rm: /home/teddy/.minikube/ca.pem
I0125 01:30:15.858261     903 exec_runner.go:151] cp: /home/teddy/.minikube/certs/ca.pem --> /home/teddy/.minikube/ca.pem (1074 bytes)
I0125 01:30:15.859037     903 exec_runner.go:144] found /home/teddy/.minikube/cert.pem, removing ...
I0125 01:30:15.859042     903 exec_runner.go:207] rm: /home/teddy/.minikube/cert.pem
I0125 01:30:15.859155     903 exec_runner.go:151] cp: /home/teddy/.minikube/certs/cert.pem --> /home/teddy/.minikube/cert.pem (1119 bytes)
I0125 01:30:15.859677     903 exec_runner.go:144] found /home/teddy/.minikube/key.pem, removing ...
I0125 01:30:15.859681     903 exec_runner.go:207] rm: /home/teddy/.minikube/key.pem
I0125 01:30:15.859767     903 exec_runner.go:151] cp: /home/teddy/.minikube/certs/key.pem --> /home/teddy/.minikube/key.pem (1675 bytes)
I0125 01:30:15.860149     903 provision.go:112] generating server cert: /home/teddy/.minikube/machines/server.pem ca-key=/home/teddy/.minikube/certs/ca.pem private-key=/home/teddy/.minikube/certs/ca-key.pem org=teddy.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0125 01:30:15.972642     903 provision.go:172] copyRemoteCerts
I0125 01:30:15.972747     903 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0125 01:30:15.972798     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:16.000232     903 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/teddy/.minikube/machines/minikube/id_rsa Username:docker}
I0125 01:30:16.099878     903 ssh_runner.go:362] scp /home/teddy/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1074 bytes)
I0125 01:30:16.462123     903 ssh_runner.go:362] scp /home/teddy/.minikube/machines/server.pem --> /etc/docker/server.pem (1200 bytes)
I0125 01:30:16.518101     903 ssh_runner.go:362] scp /home/teddy/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0125 01:30:16.562364     903 provision.go:86] duration metric: configureAuth took 776.8185ms
I0125 01:30:16.562386     903 ubuntu.go:193] setting minikube options for container-runtime
I0125 01:30:16.562793     903 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0125 01:30:16.562892     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:16.611303     903 main.go:134] libmachine: Using SSH client type: native
I0125 01:30:16.611453     903 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7ed4e0] 0x7f0660 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0125 01:30:16.611462     903 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0125 01:30:16.793317     903 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0125 01:30:16.793328     903 ubuntu.go:71] root file system type: overlay
I0125 01:30:16.793473     903 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0125 01:30:16.793545     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:16.833960     903 main.go:134] libmachine: Using SSH client type: native
I0125 01:30:16.834105     903 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7ed4e0] 0x7f0660 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0125 01:30:16.834179     903 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0125 01:30:16.966766     903 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0125 01:30:16.966841     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:16.995786     903 main.go:134] libmachine: Using SSH client type: native
I0125 01:30:16.995939     903 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x7ed4e0] 0x7f0660 <nil>  [] 0s} 127.0.0.1 49157 <nil> <nil>}
I0125 01:30:16.995951     903 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0125 01:30:17.142910     903 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0125 01:30:17.142923     903 machine.go:91] provisioned docker machine in 8.999682s
I0125 01:30:17.142930     903 start.go:300] post-start starting for "minikube" (driver="docker")
I0125 01:30:17.142935     903 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0125 01:30:17.143012     903 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0125 01:30:17.143067     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:17.171768     903 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/teddy/.minikube/machines/minikube/id_rsa Username:docker}
I0125 01:30:17.387387     903 ssh_runner.go:195] Run: cat /etc/os-release
I0125 01:30:17.391008     903 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0125 01:30:17.391035     903 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0125 01:30:17.391041     903 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0125 01:30:17.391045     903 info.go:137] Remote host: Ubuntu 20.04.5 LTS
I0125 01:30:17.391053     903 filesync.go:126] Scanning /home/teddy/.minikube/addons for local assets ...
I0125 01:30:17.404882     903 filesync.go:126] Scanning /home/teddy/.minikube/files for local assets ...
I0125 01:30:17.405431     903 start.go:303] post-start completed in 262.4938ms
I0125 01:30:17.405492     903 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0125 01:30:17.405536     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:17.439733     903 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/teddy/.minikube/machines/minikube/id_rsa Username:docker}
I0125 01:30:17.526390     903 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0125 01:30:17.530720     903 fix.go:57] fixHost completed within 14.2671734s
I0125 01:30:17.530737     903 start.go:83] releasing machines lock for "minikube", held for 14.2672113s
I0125 01:30:17.530887     903 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0125 01:30:17.656416     903 ssh_runner.go:195] Run: systemctl --version
I0125 01:30:17.656496     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:30:17.685721     903 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/teddy/.minikube/machines/minikube/id_rsa Username:docker}
I0125 01:30:17.748521     903 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0125 01:30:17.800401     903 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0125 01:30:19.763777     903 ssh_runner.go:235] Completed: curl -sS -m 2 https://registry.k8s.io/: (2.0152326s)
I0125 01:30:19.763966     903 ssh_runner.go:235] Completed: sudo systemctl cat docker.service: (1.9635477s)
I0125 01:30:19.763983     903 cruntime.go:273] skipping containerd shutdown because we are bound to it
I0125 01:30:19.764040     903 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0125 01:30:19.865934     903 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0125 01:30:19.881093     903 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0125 01:30:20.008910     903 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0125 01:30:20.081403     903 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0125 01:30:20.152993     903 ssh_runner.go:195] Run: sudo systemctl restart docker
I0125 01:30:35.106741     903 ssh_runner.go:235] Completed: sudo systemctl restart docker: (14.9537169s)
I0125 01:30:35.106836     903 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0125 01:30:35.183828     903 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0125 01:30:35.253211     903 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0125 01:30:35.263513     903 start.go:451] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0125 01:30:35.305202     903 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0125 01:30:35.308359     903 start.go:472] Will wait 60s for crictl version
I0125 01:30:35.308404     903 ssh_runner.go:195] Run: sudo crictl version
I0125 01:30:38.562753     903 ssh_runner.go:235] Completed: sudo crictl version: (3.2543346s)
I0125 01:30:38.562768     903 start.go:481] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.20
RuntimeApiVersion:  1.41.0
I0125 01:30:38.562822     903 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0125 01:30:39.866334     903 ssh_runner.go:235] Completed: docker version --format {{.Server.Version}}: (1.3034892s)
I0125 01:30:39.866420     903 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0125 01:30:40.033561     903 out.go:204] üê≥  Preparing Kubernetes v1.25.3 on Docker 20.10.20 ...
I0125 01:30:40.034061     903 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0125 01:30:40.102969     903 ssh_runner.go:195] Run: grep 192.168.49.1	host.minikube.internal$ /etc/hosts
I0125 01:30:40.108537     903 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.49.1	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0125 01:30:40.126309     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0125 01:30:40.158693     903 preload.go:132] Checking if preload exists for k8s version v1.25.3 and runtime docker
I0125 01:30:40.158761     903 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0125 01:30:40.183444     903 docker.go:613] Got preloaded images: -- stdout --
kabooley/event-bus:latest
kabooley/query:latest
kabooley/moderation:latest
kabooley/comments:latest
kabooley/posts:latest
kabooley/event-bus:<none>
kabooley/posts:<none>
kabooley/event-bus:<none>
kabooley/event-bus:<none>
kabooley/posts:<none>
kabooley/event-bus:<none>
kabooley/posts:<none>
kabooley/event-bus:<none>
kabooley/event-bus:<none>
kabooley/posts:<none>
registry.k8s.io/kube-apiserver:v1.25.3
registry.k8s.io/kube-controller-manager:v1.25.3
registry.k8s.io/kube-scheduler:v1.25.3
registry.k8s.io/kube-proxy:v1.25.3
registry.k8s.io/pause:3.8
registry.k8s.io/etcd:3.5.4-0
registry.k8s.io/coredns/coredns:v1.9.3
k8s.gcr.io/pause:3.6
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0125 01:30:40.183469     903 docker.go:543] Images already preloaded, skipping extraction
I0125 01:30:40.183539     903 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0125 01:30:40.206588     903 docker.go:613] Got preloaded images: -- stdout --
kabooley/event-bus:latest
kabooley/query:latest
kabooley/moderation:latest
kabooley/comments:latest
kabooley/posts:latest
kabooley/event-bus:<none>
kabooley/posts:<none>
kabooley/event-bus:<none>
kabooley/event-bus:<none>
kabooley/posts:<none>
kabooley/event-bus:<none>
kabooley/posts:<none>
kabooley/event-bus:<none>
kabooley/event-bus:<none>
kabooley/posts:<none>
registry.k8s.io/kube-apiserver:v1.25.3
registry.k8s.io/kube-controller-manager:v1.25.3
registry.k8s.io/kube-scheduler:v1.25.3
registry.k8s.io/kube-proxy:v1.25.3
registry.k8s.io/pause:3.8
registry.k8s.io/etcd:3.5.4-0
registry.k8s.io/coredns/coredns:v1.9.3
k8s.gcr.io/pause:3.6
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0125 01:30:40.206601     903 cache_images.go:84] Images are preloaded, skipping loading
I0125 01:30:40.206655     903 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0125 01:30:42.757521     903 ssh_runner.go:235] Completed: docker info --format {{.CgroupDriver}}: (2.5508492s)
I0125 01:30:42.757574     903 cni.go:95] Creating CNI manager for ""
I0125 01:30:42.757583     903 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0125 01:30:42.757595     903 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0125 01:30:42.757618     903 kubeadm.go:156] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.25.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false}
I0125 01:30:42.757761     903 kubeadm.go:161] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.25.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0125 01:30:42.767670     903 kubeadm.go:962] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.25.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0125 01:30:42.767733     903 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.25.3
I0125 01:30:42.829658     903 binaries.go:44] Found k8s binaries, skipping transfer
I0125 01:30:42.829722     903 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0125 01:30:42.837679     903 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (470 bytes)
I0125 01:30:42.851822     903 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0125 01:30:42.866266     903 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2031 bytes)
I0125 01:30:42.894016     903 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0125 01:30:42.897089     903 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0125 01:30:42.906696     903 certs.go:54] Setting up /home/teddy/.minikube/profiles/minikube for IP: 192.168.49.2
I0125 01:30:42.907193     903 certs.go:182] skipping minikubeCA CA generation: /home/teddy/.minikube/ca.key
I0125 01:30:42.924740     903 certs.go:182] skipping proxyClientCA CA generation: /home/teddy/.minikube/proxy-client-ca.key
I0125 01:30:42.925382     903 certs.go:298] skipping minikube-user signed cert generation: /home/teddy/.minikube/profiles/minikube/client.key
I0125 01:30:42.926781     903 certs.go:298] skipping minikube signed cert generation: /home/teddy/.minikube/profiles/minikube/apiserver.key.dd3b5fb2
I0125 01:30:42.927176     903 certs.go:298] skipping aggregator signed cert generation: /home/teddy/.minikube/profiles/minikube/proxy-client.key
I0125 01:30:42.927284     903 certs.go:388] found cert: /home/teddy/.minikube/certs/home/teddy/.minikube/certs/ca-key.pem (1675 bytes)
I0125 01:30:42.927313     903 certs.go:388] found cert: /home/teddy/.minikube/certs/home/teddy/.minikube/certs/ca.pem (1074 bytes)
I0125 01:30:42.927334     903 certs.go:388] found cert: /home/teddy/.minikube/certs/home/teddy/.minikube/certs/cert.pem (1119 bytes)
I0125 01:30:42.927350     903 certs.go:388] found cert: /home/teddy/.minikube/certs/home/teddy/.minikube/certs/key.pem (1675 bytes)
I0125 01:30:42.927852     903 ssh_runner.go:362] scp /home/teddy/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0125 01:30:42.948974     903 ssh_runner.go:362] scp /home/teddy/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0125 01:30:42.969764     903 ssh_runner.go:362] scp /home/teddy/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0125 01:30:42.990140     903 ssh_runner.go:362] scp /home/teddy/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1679 bytes)
I0125 01:30:43.010554     903 ssh_runner.go:362] scp /home/teddy/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0125 01:30:43.030374     903 ssh_runner.go:362] scp /home/teddy/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0125 01:30:43.057664     903 ssh_runner.go:362] scp /home/teddy/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0125 01:30:43.077447     903 ssh_runner.go:362] scp /home/teddy/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0125 01:30:43.122865     903 ssh_runner.go:362] scp /home/teddy/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0125 01:30:43.143571     903 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0125 01:30:43.227422     903 ssh_runner.go:195] Run: openssl version
I0125 01:30:43.304087     903 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0125 01:30:43.328466     903 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0125 01:30:43.331755     903 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Jan 18 19:09 /usr/share/ca-certificates/minikubeCA.pem
I0125 01:30:43.331777     903 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0125 01:30:43.336285     903 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0125 01:30:43.344367     903 kubeadm.go:396] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 Memory:2200 CPUs:2 DiskSize:20000 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/home/teddy:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0125 01:30:43.344545     903 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0125 01:30:43.364516     903 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0125 01:30:43.372950     903 kubeadm.go:411] found existing configuration files, will attempt cluster restart
I0125 01:30:43.372962     903 kubeadm.go:627] restartCluster start
I0125 01:30:43.373039     903 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0125 01:30:43.380646     903 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0125 01:30:43.380705     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0125 01:30:43.409134     903 kubeconfig.go:135] verify returned: extract IP: "minikube" does not appear in /home/teddy/.kube/config
I0125 01:30:43.409221     903 kubeconfig.go:146] "minikube" context is missing from /home/teddy/.kube/config - will repair!
I0125 01:30:43.409470     903 lock.go:35] WriteFile acquiring /home/teddy/.kube/config: {Name:mkc87d1dd847152325ff1308f1a4dc3454f4de2a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0125 01:30:43.572753     903 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0125 01:30:43.638420     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:43.638473     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:43.729309     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:43.929856     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:43.929951     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:43.942329     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:44.130126     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:44.130210     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:44.142363     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:44.330066     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:44.330142     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:44.342310     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:44.530017     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:44.530098     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:44.542575     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:44.730130     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:44.730226     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:44.742466     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:44.930035     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:44.930117     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:44.942659     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:45.130582     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:45.130657     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:45.143044     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:45.329554     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:45.329650     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:45.342035     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:45.529684     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:45.529759     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:45.542443     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:45.730096     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:45.730171     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:45.742567     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:45.930234     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:45.930317     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:45.942419     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.130164     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:46.130238     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:46.142599     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.329539     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:46.329640     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:46.342394     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.530422     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:46.530502     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:46.542818     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.729490     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:46.729598     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:46.742405     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.742413     903 api_server.go:165] Checking apiserver status ...
I0125 01:30:46.742469     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0125 01:30:46.754251     903 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.754268     903 kubeadm.go:602] needs reconfigure: apiserver error: timed out waiting for the condition
I0125 01:30:46.754274     903 kubeadm.go:1114] stopping kube-system containers ...
I0125 01:30:46.754340     903 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0125 01:30:46.793948     903 docker.go:444] Stopping containers: [2977cf02f877 b3ae1c45726f 1f1042464b15 0679c21c6e22 7a1683e959d1 65599659f008 7c05b66595c9 3ea2de0ecf94 6f281bf122cb 125d79e9e903 5f5a70dadc70 08d7c9bdcf83 27f3792c5bf5 b4a5ed32b55f 294bc0eaef80 ae409ea6829b bbb68ec9b626 128211812b8a a2e788855174 11d5f606b313 cbf1d7c9bda5 333c4ce5adf4 dbd23e3078a1 a69dbc06543a 825b035078ee 384f18e9e1f9]
I0125 01:30:46.794034     903 ssh_runner.go:195] Run: docker stop 2977cf02f877 b3ae1c45726f 1f1042464b15 0679c21c6e22 7a1683e959d1 65599659f008 7c05b66595c9 3ea2de0ecf94 6f281bf122cb 125d79e9e903 5f5a70dadc70 08d7c9bdcf83 27f3792c5bf5 b4a5ed32b55f 294bc0eaef80 ae409ea6829b bbb68ec9b626 128211812b8a a2e788855174 11d5f606b313 cbf1d7c9bda5 333c4ce5adf4 dbd23e3078a1 a69dbc06543a 825b035078ee 384f18e9e1f9
I0125 01:30:46.824638     903 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0125 01:30:46.836601     903 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0125 01:30:46.845161     903 kubeadm.go:155] found existing configuration files:
-rw------- 1 root root 5639 Jan 18 19:10 /etc/kubernetes/admin.conf
-rw------- 1 root root 5656 Jan 22 17:28 /etc/kubernetes/controller-manager.conf
-rw------- 1 root root 1971 Jan 18 19:11 /etc/kubernetes/kubelet.conf
-rw------- 1 root root 5600 Jan 22 17:28 /etc/kubernetes/scheduler.conf

I0125 01:30:46.845241     903 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/admin.conf
I0125 01:30:46.869844     903 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/kubelet.conf
I0125 01:30:46.890084     903 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf
I0125 01:30:46.920341     903 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/controller-manager.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/controller-manager.conf: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.920395     903 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/controller-manager.conf
I0125 01:30:46.927927     903 ssh_runner.go:195] Run: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf
I0125 01:30:46.953620     903 kubeadm.go:166] "https://control-plane.minikube.internal:8443" may not be in /etc/kubernetes/scheduler.conf - will remove: sudo grep https://control-plane.minikube.internal:8443 /etc/kubernetes/scheduler.conf: Process exited with status 1
stdout:

stderr:
I0125 01:30:46.953725     903 ssh_runner.go:195] Run: sudo rm -f /etc/kubernetes/scheduler.conf
I0125 01:30:46.970751     903 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0125 01:30:46.984457     903 kubeadm.go:704] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0125 01:30:46.984474     903 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0125 01:30:50.455313     903 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": (3.4708205s)
I0125 01:30:50.455327     903 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0125 01:30:51.607591     903 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml": (1.1522477s)
I0125 01:30:51.607612     903 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0125 01:30:51.826169     903 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0125 01:30:51.913603     903 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0125 01:30:51.957719     903 api_server.go:51] waiting for apiserver process to appear ...
I0125 01:30:51.957775     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:52.466957     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:52.967475     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:53.467739     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:53.967068     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:54.467689     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:54.967406     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:55.467571     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:55.967581     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:56.466774     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:56.967143     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:57.467354     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:57.967724     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:58.467367     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:58.967442     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:59.466824     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:30:59.966970     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:00.467093     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:00.966650     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:01.467354     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:01.967532     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:02.467518     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:02.967851     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:03.467543     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:03.966753     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:04.467747     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:04.967670     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:05.467654     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:05.967172     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:06.466655     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:06.967529     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:07.467032     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:07.967713     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:08.467008     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:08.967450     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:09.467344     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:09.967236     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:10.467555     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:10.966714     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:11.467484     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:11.967238     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:12.466719     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:12.966662     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:13.467742     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:13.478266     903 api_server.go:71] duration metric: took 21.5205499s to wait for apiserver process to appear ...
I0125 01:31:13.478279     903 api_server.go:87] waiting for apiserver healthz status ...
I0125 01:31:13.478287     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:13.479061     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35150->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:13.979500     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:13.980321     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35154->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:14.479270     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:14.479926     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35160->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:14.980080     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:14.980833     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35174->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:15.479326     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:15.480183     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35180->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:15.980016     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:15.980763     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35190->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:16.479213     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:16.481017     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:16.979816     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:16.981076     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35200->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:17.479781     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:17.480388     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:17.979502     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:17.980149     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:18.479820     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:18.480460     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:18.980149     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:18.980761     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:19.479547     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:19.480166     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35226->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:19.979156     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:19.979855     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:20.480002     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:20.480640     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:20.979968     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:20.980769     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35242->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:21.479699     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:21.480415     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35248->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:21.979250     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:21.980003     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35252->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:22.479628     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:22.480564     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:22.979989     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:22.980610     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35270->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:23.479652     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:23.480477     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:23.979507     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:23.980301     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:24.479805     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:24.480502     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:24.979533     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:24.980282     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35296->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:25.479646     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:25.480390     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35304->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:25.980187     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:25.981017     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35308->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:26.480133     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:26.480881     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35314->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:26.980013     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:26.980725     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35318->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:27.479415     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:27.480819     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:27.980258     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:27.981668     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35364->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:28.479272     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:28.480239     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35392->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:28.979569     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:28.980389     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": read tcp 127.0.0.1:35408->127.0.0.1:49154: read: connection reset by peer
I0125 01:31:29.479238     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:29.479886     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:29.980295     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:29.982009     903 api_server.go:268] stopped: https://127.0.0.1:49154/healthz: Get "https://127.0.0.1:49154/healthz": EOF
I0125 01:31:30.479199     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:34.316385     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
W0125 01:31:34.316399     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 403:
{"kind":"Status","apiVersion":"v1","metadata":{},"status":"Failure","message":"forbidden: User \"system:anonymous\" cannot get path \"/healthz\"","reason":"Forbidden","details":{},"code":403}
I0125 01:31:34.479918     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:34.716433     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:34.716470     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:34.980254     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:35.000977     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:35.001003     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:35.479512     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:35.616152     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:35.616180     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:35.980016     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:36.074613     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:36.074640     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:36.479261     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:36.576158     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:36.576191     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:36.979269     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:37.109057     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:37.109081     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:37.479895     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:37.670955     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:37.670980     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:37.979687     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:37.985220     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:37.985235     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:38.479290     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:38.485197     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
W0125 01:31:38.485220     903 api_server.go:102] status: https://127.0.0.1:49154/healthz returned error 500:
[+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/storage-object-count-tracker-hook ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/rbac/bootstrap-roles failed: reason withheld
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]poststarthook/apiservice-openapiv3-controller ok
healthz check failed
I0125 01:31:38.979205     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:39.095832     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 200:
ok
I0125 01:31:39.122801     903 api_server.go:140] control plane version: v1.25.3
I0125 01:31:39.122820     903 api_server.go:130] duration metric: took 25.6445385s to wait for apiserver health ...
I0125 01:31:39.122827     903 cni.go:95] Creating CNI manager for ""
I0125 01:31:39.122831     903 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0125 01:31:39.122837     903 system_pods.go:43] waiting for kube-system pods to appear ...
I0125 01:31:39.142553     903 system_pods.go:59] 7 kube-system pods found
I0125 01:31:39.142569     903 system_pods.go:61] "coredns-565d847f94-jm6q4" [89c6e5aa-6069-4d8d-afd1-d5cd27bd8432] Running
I0125 01:31:39.142572     903 system_pods.go:61] "etcd-minikube" [02fd4ee6-b948-499b-8bf1-0acb300d0a0f] Running
I0125 01:31:39.142575     903 system_pods.go:61] "kube-apiserver-minikube" [38f47254-8a7b-46cd-85b3-58300393404e] Running
I0125 01:31:39.142578     903 system_pods.go:61] "kube-controller-manager-minikube" [16221bef-82c0-43bf-9125-a3c312bcc0e1] Running
I0125 01:31:39.142582     903 system_pods.go:61] "kube-proxy-tz98m" [d0212713-6162-4fb1-b8d3-1fdbff7e1f58] Running
I0125 01:31:39.142585     903 system_pods.go:61] "kube-scheduler-minikube" [21fa7f60-c35b-4d2b-9565-1c07654102b6] Running
I0125 01:31:39.142587     903 system_pods.go:61] "storage-provisioner" [c34cf799-ac51-4c87-89b7-f5aa96dac350] Running
I0125 01:31:39.142600     903 system_pods.go:74] duration metric: took 19.7508ms to wait for pod list to return data ...
I0125 01:31:39.142605     903 node_conditions.go:102] verifying NodePressure condition ...
I0125 01:31:39.146709     903 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0125 01:31:39.146723     903 node_conditions.go:123] node cpu capacity is 8
I0125 01:31:39.146732     903 node_conditions.go:105] duration metric: took 4.1233ms to run NodePressure ...
I0125 01:31:39.146745     903 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml"
I0125 01:31:42.337945     903 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase addon all --config /var/tmp/minikube/kubeadm.yaml": (3.1911821s)
I0125 01:31:42.337962     903 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0125 01:31:42.344165     903 ops.go:34] apiserver oom_adj: -16
I0125 01:31:42.344174     903 kubeadm.go:631] restartCluster took 58.9712074s
I0125 01:31:42.344179     903 kubeadm.go:398] StartCluster complete in 58.9998215s
I0125 01:31:42.344192     903 settings.go:142] acquiring lock: {Name:mkc1b833adfbd025ce14eec37ed401f3dae934f2 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0125 01:31:42.344410     903 settings.go:150] Updating kubeconfig:  /home/teddy/.kube/config
I0125 01:31:42.344908     903 lock.go:35] WriteFile acquiring /home/teddy/.kube/config: {Name:mkc87d1dd847152325ff1308f1a4dc3454f4de2a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0125 01:31:42.348158     903 kapi.go:244] deployment "coredns" in namespace "kube-system" and context "minikube" rescaled to 1
I0125 01:31:42.348210     903 start.go:212] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0125 01:31:42.462308     903 out.go:177] üîé  Verifying Kubernetes components...
I0125 01:31:42.348302     903 addons.go:486] enableAddons start: toEnable=map[ambassador:false auto-pause:false cloud-spanner:false csi-hostpath-driver:false dashboard:false default-storageclass:true efk:false freshpod:false gcp-auth:false gvisor:false headlamp:false helm-tiller:false inaccel:false ingress:false ingress-dns:false istio:false istio-provisioner:false kong:false kubevirt:false logviewer:false metallb:false metrics-server:false nvidia-driver-installer:false nvidia-gpu-device-plugin:false olm:false pod-security-policy:false portainer:false registry:false registry-aliases:false registry-creds:false storage-provisioner:true storage-provisioner-gluster:false volumesnapshots:false], additional=[]
I0125 01:31:42.462409     903 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I0125 01:31:42.348413     903 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0125 01:31:42.462444     903 addons.go:227] Setting addon storage-provisioner=true in "minikube"
I0125 01:31:42.365715     903 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
W0125 01:31:42.462450     903 addons.go:236] addon storage-provisioner should already be in state true
I0125 01:31:42.462504     903 host.go:66] Checking if "minikube" exists ...
I0125 01:31:42.462530     903 addons.go:65] Setting default-storageclass=true in profile "minikube"
I0125 01:31:42.562348     903 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0125 01:31:42.562391     903 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0125 01:31:42.562604     903 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0125 01:31:42.562658     903 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0125 01:31:42.607711     903 addons.go:227] Setting addon default-storageclass=true in "minikube"
W0125 01:31:42.712223     903 addons.go:236] addon default-storageclass should already be in state true
I0125 01:31:42.712250     903 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0125 01:31:42.712253     903 host.go:66] Checking if "minikube" exists ...
I0125 01:31:42.843237     903 addons.go:419] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0125 01:31:42.843249     903 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0125 01:31:42.712659     903 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0125 01:31:42.843312     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:31:42.878242     903 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/teddy/.minikube/machines/minikube/id_rsa Username:docker}
I0125 01:31:42.878296     903 addons.go:419] installing /etc/kubernetes/addons/storageclass.yaml
I0125 01:31:42.878304     903 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0125 01:31:42.878364     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0125 01:31:42.906906     903 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:49157 SSHKeyPath:/home/teddy/.minikube/machines/minikube/id_rsa Username:docker}
I0125 01:31:43.077630     903 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.25.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0125 01:31:43.077638     903 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.25.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0125 01:31:44.730760     903 ssh_runner.go:235] Completed: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml": (2.2682909s)
I0125 01:31:44.730818     903 start.go:806] CoreDNS already contains "host.minikube.internal" host record, skipping...
I0125 01:31:44.730841     903 ssh_runner.go:235] Completed: sudo systemctl is-active --quiet service kubelet: (2.1684358s)
I0125 01:31:44.730921     903 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0125 01:31:44.763775     903 api_server.go:51] waiting for apiserver process to appear ...
I0125 01:31:44.763825     903 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0125 01:31:45.291747     903 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.25.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml: (2.2140732s)
I0125 01:31:45.291845     903 ssh_runner.go:235] Completed: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.25.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml: (2.2141587s)
I0125 01:31:45.291872     903 api_server.go:71] duration metric: took 2.9436462s to wait for apiserver process to appear ...
I0125 01:31:45.291878     903 api_server.go:87] waiting for apiserver healthz status ...
I0125 01:31:45.291886     903 api_server.go:252] Checking apiserver healthz at https://127.0.0.1:49154/healthz ...
I0125 01:31:45.487785     903 out.go:177] üåü  Enabled addons: storage-provisioner, default-storageclass
I0125 01:31:45.297086     903 api_server.go:278] https://127.0.0.1:49154/healthz returned 200:
ok
I0125 01:31:45.611597     903 addons.go:488] enableAddons completed in 3.2632867s
I0125 01:31:45.613788     903 api_server.go:140] control plane version: v1.25.3
I0125 01:31:45.613803     903 api_server.go:130] duration metric: took 321.9187ms to wait for apiserver health ...
I0125 01:31:45.613811     903 system_pods.go:43] waiting for kube-system pods to appear ...
I0125 01:31:45.625070     903 system_pods.go:59] 7 kube-system pods found
I0125 01:31:45.625154     903 system_pods.go:61] "coredns-565d847f94-jm6q4" [89c6e5aa-6069-4d8d-afd1-d5cd27bd8432] Running
I0125 01:31:45.625164     903 system_pods.go:61] "etcd-minikube" [02fd4ee6-b948-499b-8bf1-0acb300d0a0f] Running
I0125 01:31:45.625170     903 system_pods.go:61] "kube-apiserver-minikube" [38f47254-8a7b-46cd-85b3-58300393404e] Running
I0125 01:31:45.625177     903 system_pods.go:61] "kube-controller-manager-minikube" [16221bef-82c0-43bf-9125-a3c312bcc0e1] Running
I0125 01:31:45.625183     903 system_pods.go:61] "kube-proxy-tz98m" [d0212713-6162-4fb1-b8d3-1fdbff7e1f58] Running
I0125 01:31:45.625189     903 system_pods.go:61] "kube-scheduler-minikube" [21fa7f60-c35b-4d2b-9565-1c07654102b6] Running
I0125 01:31:45.625197     903 system_pods.go:61] "storage-provisioner" [c34cf799-ac51-4c87-89b7-f5aa96dac350] Running
I0125 01:31:45.625203     903 system_pods.go:74] duration metric: took 11.3859ms to wait for pod list to return data ...
I0125 01:31:45.625215     903 kubeadm.go:573] duration metric: took 3.2769879s to wait for : map[apiserver:true system_pods:true] ...
I0125 01:31:45.625229     903 node_conditions.go:102] verifying NodePressure condition ...
I0125 01:31:45.629697     903 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0125 01:31:45.629708     903 node_conditions.go:123] node cpu capacity is 8
I0125 01:31:45.629717     903 node_conditions.go:105] duration metric: took 4.4846ms to run NodePressure ...
I0125 01:31:45.629728     903 start.go:217] waiting for startup goroutines ...
I0125 01:31:45.630087     903 ssh_runner.go:195] Run: rm -f paused
I0125 01:31:53.848913     903 start.go:506] kubectl: 1.26.0, cluster: 1.25.3 (minor skew: 1)
I0125 01:31:53.963028     903 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default

* 
* ==> Docker <==
* -- Logs begin at Tue 2023-01-24 16:30:12 UTC, end at Tue 2023-01-24 16:43:43 UTC. --
Jan 24 16:30:16 minikube systemd[1]: Starting Docker Application Container Engine...
Jan 24 16:30:20 minikube systemd[1]: docker.service: Succeeded.
Jan 24 16:30:20 minikube systemd[1]: Stopped Docker Application Container Engine.
Jan 24 16:30:20 minikube systemd[1]: Starting Docker Application Container Engine...
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.698267900Z" level=info msg="Starting up"
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.813060300Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.813140800Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.813177300Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.813197900Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.963676800Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.963758100Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.963794500Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Jan 24 16:30:20 minikube dockerd[414]: time="2023-01-24T16:30:20.963812300Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Jan 24 16:30:22 minikube dockerd[414]: time="2023-01-24T16:30:22.049458700Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.219068900Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.219235500Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.219264400Z" level=warning msg="Your kernel does not support cgroup blkio throttle.read_bps_device"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.219280000Z" level=warning msg="Your kernel does not support cgroup blkio throttle.write_bps_device"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.219294800Z" level=warning msg="Your kernel does not support cgroup blkio throttle.read_iops_device"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.219309000Z" level=warning msg="Your kernel does not support cgroup blkio throttle.write_iops_device"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.241783200Z" level=info msg="Loading containers: start."
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.284780600Z" level=error msg="failed to load container" container=131f533f2e0a9848a1c0ea365275f69b729e602f55ca56d0bb9281be79e104a9 error="open /var/lib/docker/containers/131f533f2e0a9848a1c0ea365275f69b729e602f55ca56d0bb9281be79e104a9/config.v2.json: no such file or directory"
Jan 24 16:30:24 minikube dockerd[414]: time="2023-01-24T16:30:24.293634800Z" level=error msg="failed to load container" container=e481ac622faac13d1de571b345bb0fe181f699bf3bd975693a5071b272240b84 error="open /var/lib/docker/containers/e481ac622faac13d1de571b345bb0fe181f699bf3bd975693a5071b272240b84/config.v2.json: no such file or directory"
Jan 24 16:30:25 minikube dockerd[414]: time="2023-01-24T16:30:25.846091200Z" level=error msg="ae409ea6829b8081eaaeaab394fe16bb5f2b6f8108798dda8b083dd028a66089 cleanup: failed to delete container from containerd: no such container"
Jan 24 16:30:25 minikube dockerd[414]: time="2023-01-24T16:30:25.855950600Z" level=error msg="65599659f008f9f80c0bff43fc91e353a6bf35027cc21dc10c8c9f2c952ca21e cleanup: failed to delete container from containerd: no such container"
Jan 24 16:30:28 minikube dockerd[414]: time="2023-01-24T16:30:28.718375500Z" level=warning msg="Running modprobe bridge br_netfilter failed with message: modprobe: WARNING: Module bridge not found in directory /lib/modules/4.19.128-microsoft-standard\nmodprobe: WARNING: Module br_netfilter not found in directory /lib/modules/4.19.128-microsoft-standard\n, error: exit status 1"
Jan 24 16:30:29 minikube dockerd[414]: time="2023-01-24T16:30:29.261641200Z" level=info msg="Removing stale sandbox abdddc31bd031491ebb6bf60486fc34a79a7c19aeb44dc105152b1686a3c1dd6 (e1a97b87cd1dfc73e99bbad8f295347be04b48c6f932ca746f05024d491fc64c)"
Jan 24 16:30:29 minikube dockerd[414]: time="2023-01-24T16:30:29.512389000Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint 74f8106cacc8d6ca4cd95ac7601beec6858e49b1e4671404ad40ff8eaa6b5b76 31f00c5eca6bd372a9744f0137f7f757a17da900ba9499ad460c5388de126e69], retrying...."
Jan 24 16:30:30 minikube dockerd[414]: time="2023-01-24T16:30:30.088834600Z" level=info msg="Removing stale sandbox de7d2b09eed2c7b38fd8657c88245783632508b8313e63dd485a491506b9826c (810b2ced84769dd0f2bfd519a1f5e0c95d6507a4fd94037cfe1165a83dd08cfb)"
Jan 24 16:30:30 minikube dockerd[414]: time="2023-01-24T16:30:30.526379600Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint 74f8106cacc8d6ca4cd95ac7601beec6858e49b1e4671404ad40ff8eaa6b5b76 80305c11796f1fbba75a19c9165a7b976bbe0ba6c07dabf72fa7b190018c3b9d], retrying...."
Jan 24 16:30:31 minikube dockerd[414]: time="2023-01-24T16:30:31.323697100Z" level=error msg="getEndpointFromStore for eid a0f4dd152ba9f902aa8ee775c8b312995d414946c421fbfcf881141a610a64e4 failed while trying to build sandbox for cleanup: could not find endpoint a0f4dd152ba9f902aa8ee775c8b312995d414946c421fbfcf881141a610a64e4: []"
Jan 24 16:30:31 minikube dockerd[414]: time="2023-01-24T16:30:31.323746900Z" level=info msg="Removing stale sandbox f84a6dc4af4717bf4e3b9019ab350df14270cb032b863bbebc06745fb34276da (1db26336a97b807fa2edd087db120160f0fd7176d93270c8f0a002b8e0afcff6)"
Jan 24 16:30:31 minikube dockerd[414]: time="2023-01-24T16:30:31.324019700Z" level=warning msg="Failed deleting endpoint a0f4dd152ba9f902aa8ee775c8b312995d414946c421fbfcf881141a610a64e4: failed to get endpoint from store during Delete: could not find endpoint a0f4dd152ba9f902aa8ee775c8b312995d414946c421fbfcf881141a610a64e4: []\n"
Jan 24 16:30:31 minikube dockerd[414]: time="2023-01-24T16:30:31.657557400Z" level=info msg="Removing stale sandbox f8af8c6f65773b4dd24973322f820ca70af9b8d0d0328f079b1ee87644569e7c (7c05b66595c92e3cab1ce0574af4b930222a98effa2cddb9043b6be8d62d9a13)"
Jan 24 16:30:31 minikube dockerd[414]: time="2023-01-24T16:30:31.984967200Z" level=warning msg="Error (Unable to complete atomic operation, key modified) deleting object [endpoint 74f8106cacc8d6ca4cd95ac7601beec6858e49b1e4671404ad40ff8eaa6b5b76 d2a6679fd24e3ed075153185d4733a2062f2c8c1d72c1fe8513d519a99d75d87], retrying...."
Jan 24 16:30:32 minikube dockerd[414]: time="2023-01-24T16:30:32.519757800Z" level=error msg="getEndpointFromStore for eid d411760d5c5307989f4c0947863328299496ca9fa7cbec4fdfc9b79fa9c4e4c6 failed while trying to build sandbox for cleanup: could not find endpoint d411760d5c5307989f4c0947863328299496ca9fa7cbec4fdfc9b79fa9c4e4c6: []"
Jan 24 16:30:32 minikube dockerd[414]: time="2023-01-24T16:30:32.519819800Z" level=info msg="Removing stale sandbox 5b9ecf8ac40b42bab0ab96fe13e96a8f7d896f051927cdbca52e017df16d242b (24ceb51c6882f297ad02602fa32f5a06a7f8eda006ec58e3201e679f940a594f)"
Jan 24 16:30:32 minikube dockerd[414]: time="2023-01-24T16:30:32.520053100Z" level=warning msg="Failed deleting endpoint d411760d5c5307989f4c0947863328299496ca9fa7cbec4fdfc9b79fa9c4e4c6: failed to get endpoint from store during Delete: could not find endpoint d411760d5c5307989f4c0947863328299496ca9fa7cbec4fdfc9b79fa9c4e4c6: []\n"
Jan 24 16:30:32 minikube dockerd[414]: time="2023-01-24T16:30:32.620290200Z" level=info msg="Fixing inconsistent endpoint_cnt for network bridge. Expected=0, Actual=2"
Jan 24 16:30:33 minikube dockerd[414]: time="2023-01-24T16:30:33.445548700Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Jan 24 16:30:33 minikube dockerd[414]: time="2023-01-24T16:30:33.925536200Z" level=info msg="Loading containers: done."
Jan 24 16:30:34 minikube dockerd[414]: time="2023-01-24T16:30:34.445872100Z" level=info msg="Docker daemon" commit=03df974 graphdriver(s)=overlay2 version=20.10.20
Jan 24 16:30:34 minikube dockerd[414]: time="2023-01-24T16:30:34.457049200Z" level=info msg="Daemon has completed initialization"
Jan 24 16:30:35 minikube dockerd[414]: time="2023-01-24T16:30:35.097161400Z" level=info msg="API listen on [::]:2376"
Jan 24 16:30:35 minikube systemd[1]: Started Docker Application Container Engine.
Jan 24 16:30:35 minikube dockerd[414]: time="2023-01-24T16:30:35.110896500Z" level=info msg="API listen on /var/run/docker.sock"
Jan 24 16:32:59 minikube dockerd[414]: time="2023-01-24T16:32:59.988618400Z" level=info msg="ignoring event" container=3a4e0263cf3147f9e745821e7a4a342889d6b9b5fe4abe5e5f0fdc55193971ba module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 24 16:33:03 minikube dockerd[414]: time="2023-01-24T16:33:03.244960600Z" level=error msg="Failed to compute size of container rootfs 2977cf02f87714fa04683d70f2748d24842f053f7c5c5c8fac7ad76edc6eb074: mount does not exist"
Jan 24 16:38:54 minikube dockerd[414]: time="2023-01-24T16:38:54.420222100Z" level=warning msg="reference for unknown type: " digest="sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f" remote="registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f"
Jan 24 16:39:07 minikube dockerd[414]: time="2023-01-24T16:39:07.333930900Z" level=info msg="ignoring event" container=d4321fd219846b09fb7bf59825d714f37eaac2a5889f364d56ca1e60ede1db90 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 24 16:39:09 minikube dockerd[414]: time="2023-01-24T16:39:09.125047100Z" level=info msg="ignoring event" container=a36874f82550627a21d81c2f65df72e2c27381d322f24c539abd468d89dce5f9 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 24 16:39:11 minikube dockerd[414]: time="2023-01-24T16:39:11.854512100Z" level=info msg="ignoring event" container=f26da7bcfc4024c7d505a26f68a376879960a6ee25d930bb75817516acbf53f6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 24 16:39:11 minikube dockerd[414]: time="2023-01-24T16:39:11.854609400Z" level=info msg="ignoring event" container=fbab387fa2923b60386e473611bd6a7595515053900827e1dcb2d7a05f1589c1 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 24 16:39:36 minikube dockerd[414]: time="2023-01-24T16:39:36.268159700Z" level=warning msg="reference for unknown type: " digest="sha256:4ba73c697770664c1e00e9f968de14e08f606ff961c76e5d7033a4a9c593c629" remote="registry.k8s.io/ingress-nginx/controller@sha256:4ba73c697770664c1e00e9f968de14e08f606ff961c76e5d7033a4a9c593c629"
Jan 24 16:40:05 minikube dockerd[414]: time="2023-01-24T16:40:05.133675600Z" level=warning msg="reference for unknown type: " digest="sha256:5516d103a9c2ecc4f026efbd4b40662ce22dc1f824fb129ed121460aaa5c47f8" remote="k8s.gcr.io/ingress-nginx/controller@sha256:5516d103a9c2ecc4f026efbd4b40662ce22dc1f824fb129ed121460aaa5c47f8"
Jan 24 16:40:27 minikube dockerd[414]: time="2023-01-24T16:40:27.124812000Z" level=info msg="ignoring event" container=890ab108e1a11d43086a93fe127311d8cdf0c8fbb37708a2449a0ba4cca461c6 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"
Jan 24 16:40:31 minikube dockerd[414]: time="2023-01-24T16:40:31.302826000Z" level=info msg="ignoring event" container=3f2986ed5539a97bfd229d2efc49dd32450ddef37affe257d76fdc22cc1df8d5 module=libcontainerd namespace=moby topic=/tasks/delete type="*events.TaskDelete"

* 
* ==> container status <==
* CONTAINER           IMAGE                                                                                                                        CREATED             STATE               NAME                      ATTEMPT             POD ID
4bb36dc1998fb       k8s.gcr.io/ingress-nginx/controller@sha256:5516d103a9c2ecc4f026efbd4b40662ce22dc1f824fb129ed121460aaa5c47f8                  3 minutes ago       Running             controller                0                   b73466abfafa7
a36874f825506       registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f   4 minutes ago       Exited              patch                     0                   fbab387fa2923
d4321fd219846       registry.k8s.io/ingress-nginx/kube-webhook-certgen@sha256:39c5b2e3310dc4264d638ad28d9d1d96c4cbb2b2dcfb52368fe4e3c63f61e10f   4 minutes ago       Exited              create                    0                   f26da7bcfc402
c5eb05ca28395       6e38f40d628db                                                                                                                10 minutes ago      Running             storage-provisioner       11                  dd610e3dfdde5
9cab816eb38ab       kabooley/query@sha256:64e447346f9ee889893e31659764e9cf8f891e11305102bbe3fb128a6ee3437d                                       11 minutes ago      Running             query                     1                   a3f4e8f452cf3
a71794c6b336b       kabooley/comments@sha256:b339a9a5cd3fe42ddc29fcd2a8d246c33bc914646290be1a651abd02eec22653                                    11 minutes ago      Running             comments                  1                   ccf759887259b
3033b500827dd       kabooley/event-bus@sha256:ee405198ffce3eab75bfe44ce09b11f3b271b6d0ae7635e5b842282f1189bca3                                   11 minutes ago      Running             event-bus                 1                   991428a7c9fe3
6521256b53fcf       kabooley/moderation@sha256:f0cd0d1db1fbec537e8435b1b293b809b4a882c3730c2c8c7e1563ec76a0df87                                  11 minutes ago      Running             moderation                1                   b2bfae2ad14b0
4862b022cbd45       kabooley/posts@sha256:2d757cf72ab541d02da1966ef683c291dca60bb5ad97a998a044c380201fb8f2                                       11 minutes ago      Running             posts                     1                   23701029fcc52
4441fba506d84       5185b96f0becf                                                                                                                11 minutes ago      Running             coredns                   6                   0c683843cd611
3a4e0263cf314       6e38f40d628db                                                                                                                11 minutes ago      Exited              storage-provisioner       10                  dd610e3dfdde5
011033b142991       beaaf00edd38a                                                                                                                11 minutes ago      Running             kube-proxy                6                   d1b0d27e832bf
0860f5644563d       0346dbd74bcb9                                                                                                                12 minutes ago      Running             kube-apiserver            6                   612f940c98308
00f18cd045ad0       6d23ec0e8b87e                                                                                                                12 minutes ago      Running             kube-scheduler            6                   0d19f9a4f0dc1
a2467760f9415       6039992312758                                                                                                                12 minutes ago      Running             kube-controller-manager   8                   e23c385baeb85
bde099f4f903a       a8a176a5d5d69                                                                                                                12 minutes ago      Running             etcd                      6                   2a224bba7cdfa
624d7d7b69170       kabooley/event-bus@sha256:ee405198ffce3eab75bfe44ce09b11f3b271b6d0ae7635e5b842282f1189bca3                                   46 hours ago        Exited              event-bus                 0                   24ceb51c6882f
8cd0767ca9716       kabooley/moderation@sha256:f0cd0d1db1fbec537e8435b1b293b809b4a882c3730c2c8c7e1563ec76a0df87                                  47 hours ago        Exited              moderation                0                   c86aa4a9ac0e3
4d9024d71ee7a       kabooley/comments@sha256:b339a9a5cd3fe42ddc29fcd2a8d246c33bc914646290be1a651abd02eec22653                                    47 hours ago        Exited              comments                  0                   e1a97b87cd1df
7a99a4fbf3d65       kabooley/query@sha256:64e447346f9ee889893e31659764e9cf8f891e11305102bbe3fb128a6ee3437d                                       47 hours ago        Exited              query                     0                   1db26336a97b8
1c360054dcf15       kabooley/posts@sha256:2d757cf72ab541d02da1966ef683c291dca60bb5ad97a998a044c380201fb8f2                                       47 hours ago        Exited              posts                     0                   810b2ced84769
b3ae1c45726f8       6039992312758                                                                                                                47 hours ago        Exited              kube-controller-manager   7                   ae409ea6829b8
1f1042464b155       5185b96f0becf                                                                                                                47 hours ago        Exited              coredns                   5                   7c05b66595c92
7a1683e959d12       beaaf00edd38a                                                                                                                47 hours ago        Exited              kube-proxy                5                   3ea2de0ecf94b
6f281bf122cbb       6d23ec0e8b87e                                                                                                                47 hours ago        Exited              kube-scheduler            5                   b4a5ed32b55fb
5f5a70dadc707       a8a176a5d5d69                                                                                                                47 hours ago        Exited              etcd                      5                   294bc0eaef809
08d7c9bdcf83b       0346dbd74bcb9                                                                                                                47 hours ago        Exited              kube-apiserver            5                   27f3792c5bf5d

* 
* ==> coredns [1f1042464b15] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
.:53
[INFO] plugin/reload: Running configuration SHA512 = eff20e86b4fd2b9878e9c34205d7ba141ff41613cbdadb71e63d4a8be6caff7d1fbccef3edfe618baf8958049a58d98ae28ea781e3e7cdf1cc90820da8e01a6d
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11
[INFO] SIGTERM: Shutting down servers then terminating
[INFO] plugin/health: Going into lameduck mode for 5s

* 
* ==> coredns [4441fba506d8] <==
* [INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
[INFO] plugin/kubernetes: waiting for Kubernetes API before starting server
.:53
[INFO] plugin/reload: Running configuration SHA512 = eff20e86b4fd2b9878e9c34205d7ba141ff41613cbdadb71e63d4a8be6caff7d1fbccef3edfe618baf8958049a58d98ae28ea781e3e7cdf1cc90820da8e01a6d
CoreDNS-1.9.3
linux/amd64, go1.18.2, 45b0a11

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=986b1ebd987211ed16f8cc10aed7d2c42fc8392f
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_01_19T04_11_12_0700
                    minikube.k8s.io/version=v1.28.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Wed, 18 Jan 2023 19:10:39 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Tue, 24 Jan 2023 16:43:44 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Tue, 24 Jan 2023 16:40:59 +0000   Wed, 18 Jan 2023 19:10:37 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Tue, 24 Jan 2023 16:40:59 +0000   Wed, 18 Jan 2023 19:10:37 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Tue, 24 Jan 2023 16:40:59 +0000   Wed, 18 Jan 2023 19:10:37 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Tue, 24 Jan 2023 16:40:59 +0000   Wed, 18 Jan 2023 19:10:50 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                8
  ephemeral-storage:  263174212Ki
  hugepages-2Mi:      0
  memory:             3061528Ki
  pods:               110
Allocatable:
  cpu:                8
  ephemeral-storage:  263174212Ki
  hugepages-2Mi:      0
  memory:             3061528Ki
  pods:               110
System Info:
  Machine ID:                 996614ec4c814b87b7ec8ebee3d0e8c9
  System UUID:                996614ec4c814b87b7ec8ebee3d0e8c9
  Boot ID:                    d540b63b-b688-455b-9391-f6448addfcaf
  Kernel Version:             4.19.128-microsoft-standard
  OS Image:                   Ubuntu 20.04.5 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.20
  Kubelet Version:            v1.25.3
  Kube-Proxy Version:         v1.25.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (13 in total)
  Namespace                   Name                                         CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                         ------------  ----------  ---------------  -------------  ---
  default                     comments-depl-554fddcdf8-vcm8f               0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         46h
  default                     event-bus-depl-7dccf69b77-5srzh              0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         46h
  default                     moderation-depl-6ffdbb65d8-phg47             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         46h
  default                     posts-depl-577f4d78-nk8jk                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         46h
  default                     query-depl-7df9688c4d-9p272                  0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         46h
  ingress-nginx               ingress-nginx-controller-5959f988fd-sr6q9    100m (1%!)(MISSING)     0 (0%!)(MISSING)      90Mi (3%!)(MISSING)        0 (0%!)(MISSING)         4m19s
  kube-system                 coredns-565d847f94-jm6q4                     100m (1%!)(MISSING)     0 (0%!)(MISSING)      70Mi (2%!)(MISSING)        170Mi (5%!)(MISSING)     5d21h
  kube-system                 etcd-minikube                                100m (1%!)(MISSING)     0 (0%!)(MISSING)      100Mi (3%!)(MISSING)       0 (0%!)(MISSING)         5d21h
  kube-system                 kube-apiserver-minikube                      250m (3%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         5d21h
  kube-system                 kube-controller-manager-minikube             200m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         5d21h
  kube-system                 kube-proxy-tz98m                             0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         5d21h
  kube-system                 kube-scheduler-minikube                      100m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         5d21h
  kube-system                 storage-provisioner                          0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         5d21h
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (10%!)(MISSING)  0 (0%!)(MISSING)
  memory             260Mi (8%!)(MISSING)  170Mi (5%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age                From             Message
  ----    ------                   ----               ----             -------
  Normal  Starting                 10m                kube-proxy       
  Normal  Starting                 47h                kube-proxy       
  Normal  NodeHasSufficientPID     47h (x7 over 47h)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  Starting                 47h                kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  47h                kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  47h (x8 over 47h)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    47h (x8 over 47h)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  RegisteredNode           47h                node-controller  Node minikube event: Registered Node minikube in Controller
  Normal  Starting                 12m                kubelet          Starting kubelet.
  Normal  NodeHasSufficientMemory  12m (x8 over 12m)  kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    12m (x8 over 12m)  kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     12m (x7 over 12m)  kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeAllocatableEnforced  12m                kubelet          Updated Node Allocatable limit across pods
  Normal  RegisteredNode           11m                node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Jan24 16:27] WSL2: Performing memory compaction.
[Jan24 16:29] WSL2: Performing memory compaction.
[Jan24 16:30] cgroup: runc (1316) created nested cgroup for controller "memory" which has incomplete hierarchy support. Nested cgroups may change behavior in the future.
[  +0.000002] cgroup: "memory" requires setting use_hierarchy to 1 on the root
[ +12.182059] WSL2: Performing memory compaction.
[Jan24 16:31] WSL2: Performing memory compaction.
[ +14.810098] ------------[ cut here ]------------
[  +0.000001] rq->tmp_alone_branch != &rq->leaf_cfs_rq_list
[  +0.000933] WARNING: CPU: 2 PID: 0 at kernel/sched/fair.c:375 enqueue_task_fair+0x73d/0x760
[  +0.000001] Modules linked in:
[  +0.000003] CPU: 2 PID: 0 Comm: swapper/2 Not tainted 4.19.128-microsoft-standard #1
[  +0.000002] RIP: 0010:enqueue_task_fair+0x73d/0x760
[  +0.000001] Code: 85 30 01 00 00 e9 af f9 ff ff 80 3d 8e ef 43 01 00 0f 85 61 fa ff ff 48 c7 c7 00 75 1d 82 c6 05 7a ef 43 01 01 e8 7d 62 fc ff <0f> 0b e9 47 fa ff ff 49 8b 84 24 d0 09 00 00 80 78 58 00 0f 85 1a
[  +0.000000] RSP: 0018:ffff8880bca83e50 EFLAGS: 00010082
[  +0.000001] RAX: 0000000000000000 RBX: 0000000000000000 RCX: 0000000000000000
[  +0.000001] RDX: 000000000000002d RSI: ffffffff82b6a26d RDI: 0000000000000046
[  +0.000000] RBP: ffff88800bf44200 R08: ffffffffff692822 R09: 000000000001eec0
[  +0.000000] R10: 00000bb15fee2330 R11: 0000000000000001 R12: ffff8880bca9f600
[  +0.000001] R13: afb504000afb5041 R14: 000003726c6d90e4 R15: 0000000000000001
[  +0.000001] FS:  0000000000000000(0000) GS:ffff8880bca80000(0000) knlGS:0000000000000000
[  +0.000000] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033
[  +0.000001] CR2: 00007f2530dca000 CR3: 000000000240a005 CR4: 00000000001606a0
[  +0.000001] Call Trace:
[  +0.000455]  <IRQ>
[  +0.000109]  ttwu_do_activate+0x49/0x90
[  +0.000034]  try_to_wake_up+0x1dd/0x480
[  +0.000065]  ? __hrtimer_init+0x90/0x90
[  +0.000002]  hrtimer_wakeup+0x1e/0x30
[  +0.000239]  __hrtimer_run_queues+0x100/0x280
[  +0.000002]  hrtimer_interrupt+0xf4/0x210
[  +0.000284]  hv_stimer0_isr+0x20/0x30
[  +0.000462]  hv_stimer0_vector_handler+0x3b/0x70
[  +0.000284]  hv_stimer0_callback_vector+0xf/0x20
[  +0.000018]  </IRQ>
[  +0.000003] RIP: 0010:native_safe_halt+0xe/0x10
[  +0.000000] Code: 1f 44 00 00 e9 c5 fe ff ff 0f 0b eb 94 0f 0b e9 04 ff ff ff 90 90 90 90 90 90 90 90 e9 07 00 00 00 0f 00 2d d4 1d 53 00 fb f4 <c3> 90 e9 07 00 00 00 0f 00 2d c4 1d 53 00 f4 c3 90 90 0f 1f 44 00
[  +0.000001] RSP: 0018:ffffc90000093ec8 EFLAGS: 00000246 ORIG_RAX: ffffffffffffff12
[  +0.000001] RAX: ffffffff81ae69f0 RBX: 0000000000000002 RCX: ffffffff82441c10
[  +0.000000] RDX: 000000000007fae6 RSI: ffffffff8243f878 RDI: 000003726f293536
[  +0.000001] RBP: 0000000000000002 R08: ffffffffff678e12 R09: 000000000001eec0
[  +0.000018] R10: 00000bb15fa193bf R11: 0000000000000000 R12: ffff88800fdeb800
[  +0.000001] R13: 0000000000000000 R14: 0000000000000000 R15: 0000000000000000
[  +0.000002]  ? __cpuidle_text_start+0x8/0x8
[  +0.000067]  default_idle+0x1c/0x140
[  +0.000001]  do_idle+0xe5/0x110
[  +0.000002]  cpu_startup_entry+0x6f/0x80
[  +0.000049]  start_secondary+0x195/0x1d0
[  +0.000301]  secondary_startup_64+0xa4/0xb0
[  +0.000205] ---[ end trace daebd0f28044cb60 ]---
[Jan24 16:32] WSL2: Performing memory compaction.
[Jan24 16:33] WSL2: Performing memory compaction.
[Jan24 16:34] WSL2: Performing memory compaction.
[Jan24 16:35] WSL2: Performing memory compaction.
[Jan24 16:36] WSL2: Performing memory compaction.
[Jan24 16:37] WSL2: Performing memory compaction.
[Jan24 16:38] WSL2: Performing memory compaction.
[Jan24 16:39] WSL2: Performing memory compaction.
[Jan24 16:40] WSL2: Performing memory compaction.
[Jan24 16:42] WSL2: Performing memory compaction.
[Jan24 16:43] WSL2: Performing memory compaction.

* 
* ==> etcd [5f5a70dadc70] <==
* {"level":"warn","ts":"2023-01-22T18:27:02.474Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"509.9818ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-01-22T18:27:02.474Z","caller":"traceutil/trace.go:171","msg":"trace[198551636] range","detail":"{range_begin:/registry/poddisruptionbudgets/; range_end:/registry/poddisruptionbudgets0; response_count:0; response_revision:15677; }","duration":"493.6604ms","start":"2023-01-22T18:27:01.980Z","end":"2023-01-22T18:27:02.474Z","steps":["trace[198551636] 'agreement among raft nodes before linearized reading'  (duration: 229.9978ms)","trace[198551636] 'count revisions from in-memory index tree'  (duration: 263.6104ms)"],"step_count":2}
{"level":"info","ts":"2023-01-22T18:27:02.474Z","caller":"traceutil/trace.go:171","msg":"trace[114078441] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:15677; }","duration":"510.0174ms","start":"2023-01-22T18:27:01.964Z","end":"2023-01-22T18:27:02.474Z","steps":["trace[114078441] 'agreement among raft nodes before linearized reading'  (duration: 246.3579ms)","trace[114078441] 'range keys from in-memory index tree'  (duration: 263.6161ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:02.474Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-22T18:27:01.964Z","time spent":"510.0585ms","remote":"127.0.0.1:59134","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":29,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2023-01-22T18:27:02.474Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-22T18:27:01.980Z","time spent":"493.7021ms","remote":"127.0.0.1:59202","response type":"/etcdserverpb.KV/Range","request count":0,"request size":68,"response count":0,"response size":29,"request content":"key:\"/registry/poddisruptionbudgets/\" range_end:\"/registry/poddisruptionbudgets0\" count_only:true "}
{"level":"info","ts":"2023-01-22T18:27:04.088Z","caller":"traceutil/trace.go:171","msg":"trace[1510884016] linearizableReadLoop","detail":"{readStateIndex:20008; appliedIndex:20008; }","duration":"124.3478ms","start":"2023-01-22T18:27:03.964Z","end":"2023-01-22T18:27:04.088Z","steps":["trace[1510884016] 'read index received'  (duration: 124.3409ms)","trace[1510884016] 'applied index is now lower than readState.Index'  (duration: 6¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:04.222Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"257.8909ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-01-22T18:27:04.222Z","caller":"traceutil/trace.go:171","msg":"trace[2134622177] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:15678; }","duration":"257.971ms","start":"2023-01-22T18:27:03.964Z","end":"2023-01-22T18:27:04.222Z","steps":["trace[2134622177] 'agreement among raft nodes before linearized reading'  (duration: 124.45ms)","trace[2134622177] 'range keys from in-memory index tree'  (duration: 133.4255ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:05.742Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"118.4278ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:27:05.743Z","caller":"traceutil/trace.go:171","msg":"trace[121882364] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15679; }","duration":"118.5279ms","start":"2023-01-22T18:27:05.624Z","end":"2023-01-22T18:27:05.743Z","steps":["trace[121882364] 'agreement among raft nodes before linearized reading'  (duration: 89.5821ms)","trace[121882364] 'range keys from in-memory index tree'  (duration: 28.8126ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:06.093Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"113.2092ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-01-22T18:27:06.093Z","caller":"traceutil/trace.go:171","msg":"trace[1931853008] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:15680; }","duration":"113.3499ms","start":"2023-01-22T18:27:05.979Z","end":"2023-01-22T18:27:06.093Z","steps":["trace[1931853008] 'range keys from in-memory index tree'  (duration: 113.0561ms)"],"step_count":1}
{"level":"info","ts":"2023-01-22T18:27:12.244Z","caller":"traceutil/trace.go:171","msg":"trace[1673627723] linearizableReadLoop","detail":"{readStateIndex:20016; appliedIndex:20016; }","duration":"279.4864ms","start":"2023-01-22T18:27:11.964Z","end":"2023-01-22T18:27:12.244Z","steps":["trace[1673627723] 'read index received'  (duration: 279.4794ms)","trace[1673627723] 'applied index is now lower than readState.Index'  (duration: 6.3¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:12.385Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"420.3982ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-01-22T18:27:12.385Z","caller":"traceutil/trace.go:171","msg":"trace[1536343874] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:15684; }","duration":"420.5083ms","start":"2023-01-22T18:27:11.964Z","end":"2023-01-22T18:27:12.385Z","steps":["trace[1536343874] 'agreement among raft nodes before linearized reading'  (duration: 279.5894ms)","trace[1536343874] 'range keys from in-memory index tree'  (duration: 140.7891ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:12.385Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-22T18:27:11.964Z","time spent":"420.5697ms","remote":"127.0.0.1:59134","response type":"/etcdserverpb.KV/Range","request count":0,"request size":18,"response count":0,"response size":29,"request content":"key:\"/registry/health\" "}
{"level":"warn","ts":"2023-01-22T18:27:14.156Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"184.4596ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-01-22T18:27:14.156Z","caller":"traceutil/trace.go:171","msg":"trace[2009880911] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:15685; }","duration":"184.5638ms","start":"2023-01-22T18:27:13.971Z","end":"2023-01-22T18:27:14.156Z","steps":["trace[2009880911] 'agreement among raft nodes before linearized reading'  (duration: 26.1783ms)","trace[2009880911] 'range keys from in-memory index tree'  (duration: 158.2635ms)"],"step_count":2}
{"level":"info","ts":"2023-01-22T18:27:15.798Z","caller":"traceutil/trace.go:171","msg":"trace[1821378678] linearizableReadLoop","detail":"{readStateIndex:20019; appliedIndex:20019; }","duration":"150.5653ms","start":"2023-01-22T18:27:15.648Z","end":"2023-01-22T18:27:15.798Z","steps":["trace[1821378678] 'read index received'  (duration: 150.5497ms)","trace[1821378678] 'applied index is now lower than readState.Index'  (duration: 13.6¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:15.882Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"233.7116ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:27:15.882Z","caller":"traceutil/trace.go:171","msg":"trace[1833507838] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15686; }","duration":"233.8478ms","start":"2023-01-22T18:27:15.648Z","end":"2023-01-22T18:27:15.882Z","steps":["trace[1833507838] 'agreement among raft nodes before linearized reading'  (duration: 150.7942ms)","trace[1833507838] 'range keys from in-memory index tree'  (duration: 82.8694ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:19.069Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"103.5288ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:5"}
{"level":"info","ts":"2023-01-22T18:27:19.069Z","caller":"traceutil/trace.go:171","msg":"trace[1100126514] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:15689; }","duration":"103.6607ms","start":"2023-01-22T18:27:18.966Z","end":"2023-01-22T18:27:19.069Z","steps":["trace[1100126514] 'range keys from in-memory index tree'  (duration: 103.4448ms)"],"step_count":1}
{"level":"info","ts":"2023-01-22T18:27:25.712Z","caller":"traceutil/trace.go:171","msg":"trace[863188299] transaction","detail":"{read_only:false; response_revision:15693; number_of_response:1; }","duration":"124.731ms","start":"2023-01-22T18:27:25.588Z","end":"2023-01-22T18:27:25.712Z","steps":["trace[863188299] 'process raft request'  (duration: 28.2798ms)","trace[863188299] 'compare'  (duration: 96.2988ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:27:40.201Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"125.5422ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/\" range_end:\"/registry/configmaps0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2023-01-22T18:27:40.201Z","caller":"traceutil/trace.go:171","msg":"trace[1972537486] range","detail":"{range_begin:/registry/configmaps/; range_end:/registry/configmaps0; response_count:0; response_revision:15704; }","duration":"125.635ms","start":"2023-01-22T18:27:40.075Z","end":"2023-01-22T18:27:40.201Z","steps":["trace[1972537486] 'agreement among raft nodes before linearized reading'  (duration: 89.142ms)","trace[1972537486] 'count revisions from in-memory index tree'  (duration: 36.3651ms)"],"step_count":2}
{"level":"info","ts":"2023-01-22T18:28:05.696Z","caller":"traceutil/trace.go:171","msg":"trace[1534532161] transaction","detail":"{read_only:false; response_revision:15721; number_of_response:1; }","duration":"103.4414ms","start":"2023-01-22T18:28:05.593Z","end":"2023-01-22T18:28:05.696Z","steps":["trace[1534532161] 'process raft request'  (duration: 27.7513ms)","trace[1534532161] 'compare'  (duration: 75.5438ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:28:15.768Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"144.3236ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:28:15.768Z","caller":"traceutil/trace.go:171","msg":"trace[92846548] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15728; }","duration":"144.4595ms","start":"2023-01-22T18:28:15.623Z","end":"2023-01-22T18:28:15.768Z","steps":["trace[92846548] 'agreement among raft nodes before linearized reading'  (duration: 28.5365ms)","trace[92846548] 'range keys from in-memory index tree'  (duration: 115.7539ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:28:25.840Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"201.7937ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:28:25.840Z","caller":"traceutil/trace.go:171","msg":"trace[236297573] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15735; }","duration":"201.8948ms","start":"2023-01-22T18:28:25.638Z","end":"2023-01-22T18:28:25.840Z","steps":["trace[236297573] 'agreement among raft nodes before linearized reading'  (duration: 56.9321ms)","trace[236297573] 'range keys from in-memory index tree'  (duration: 144.8146ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:28:35.753Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"127.747ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:28:35.753Z","caller":"traceutil/trace.go:171","msg":"trace[51601250] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15742; }","duration":"127.8335ms","start":"2023-01-22T18:28:35.626Z","end":"2023-01-22T18:28:35.753Z","steps":["trace[51601250] 'agreement among raft nodes before linearized reading'  (duration: 30.9671ms)","trace[51601250] 'range keys from in-memory index tree'  (duration: 96.749ms)"],"step_count":2}
{"level":"info","ts":"2023-01-22T18:28:55.710Z","caller":"traceutil/trace.go:171","msg":"trace[733266735] transaction","detail":"{read_only:false; response_revision:15756; number_of_response:1; }","duration":"113.7726ms","start":"2023-01-22T18:28:55.597Z","end":"2023-01-22T18:28:55.710Z","steps":["trace[733266735] 'process raft request'  (duration: 18.6957ms)","trace[733266735] 'compare'  (duration: 94.8221ms)"],"step_count":2}
{"level":"info","ts":"2023-01-22T18:29:03.207Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":15551}
{"level":"info","ts":"2023-01-22T18:29:03.207Z","caller":"traceutil/trace.go:171","msg":"trace[2117950921] compact","detail":"{revision:15551; response_revision:15762; }","duration":"104.0016ms","start":"2023-01-22T18:29:03.103Z","end":"2023-01-22T18:29:03.207Z","steps":["trace[2117950921] 'check and update compact revision'  (duration: 81.9882ms)"],"step_count":1}
{"level":"info","ts":"2023-01-22T18:29:03.208Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":15551,"took":"1.0876ms"}
{"level":"warn","ts":"2023-01-22T18:29:05.732Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"104.4795ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018601103970821 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:15756 > success:<request_put:<key:\"/registry/masterleases/192.168.49.2\" value_size:66 lease:8128018601103970819 >> failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >>","response":"size:16"}
{"level":"info","ts":"2023-01-22T18:29:05.732Z","caller":"traceutil/trace.go:171","msg":"trace[162215002] transaction","detail":"{read_only:false; response_revision:15764; number_of_response:1; }","duration":"133.942ms","start":"2023-01-22T18:29:05.598Z","end":"2023-01-22T18:29:05.732Z","steps":["trace[162215002] 'process raft request'  (duration: 29.2405ms)","trace[162215002] 'compare'  (duration: 104.36ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:29:15.733Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"110.9699ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:29:15.733Z","caller":"traceutil/trace.go:171","msg":"trace[931471257] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15771; }","duration":"111.062ms","start":"2023-01-22T18:29:15.622Z","end":"2023-01-22T18:29:15.733Z","steps":["trace[931471257] 'agreement among raft nodes before linearized reading'  (duration: 20.276ms)","trace[931471257] 'range keys from in-memory index tree'  (duration: 90.663ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:29:26.047Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"307.2046ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018601103970916 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:15771 > success:<request_put:<key:\"/registry/masterleases/192.168.49.2\" value_size:66 lease:8128018601103970914 >> failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >>","response":"size:16"}
{"level":"info","ts":"2023-01-22T18:29:26.047Z","caller":"traceutil/trace.go:171","msg":"trace[1739808129] transaction","detail":"{read_only:false; response_revision:15778; number_of_response:1; }","duration":"451.8116ms","start":"2023-01-22T18:29:25.595Z","end":"2023-01-22T18:29:26.047Z","steps":["trace[1739808129] 'process raft request'  (duration: 144.4275ms)","trace[1739808129] 'compare'  (duration: 307.0622ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:29:26.047Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-22T18:29:25.595Z","time spent":"451.9672ms","remote":"127.0.0.1:59136","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":117,"response count":0,"response size":40,"request content":"compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:15771 > success:<request_put:<key:\"/registry/masterleases/192.168.49.2\" value_size:66 lease:8128018601103970914 >> failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >"}
{"level":"warn","ts":"2023-01-22T18:29:28.726Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"134.6538ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/clusterroles/\" range_end:\"/registry/clusterroles0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2023-01-22T18:29:28.726Z","caller":"traceutil/trace.go:171","msg":"trace[2009147060] range","detail":"{range_begin:/registry/clusterroles/; range_end:/registry/clusterroles0; response_count:0; response_revision:15780; }","duration":"134.745ms","start":"2023-01-22T18:29:28.592Z","end":"2023-01-22T18:29:28.726Z","steps":["trace[2009147060] 'agreement among raft nodes before linearized reading'  (duration: 47.4787ms)","trace[2009147060] 'count revisions from in-memory index tree'  (duration: 87.1591ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:29:32.185Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"131.1784ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/pods/\" range_end:\"/registry/pods0\" count_only:true ","response":"range_response_count:0 size:7"}
{"level":"info","ts":"2023-01-22T18:29:32.185Z","caller":"traceutil/trace.go:171","msg":"trace[56263645] range","detail":"{range_begin:/registry/pods/; range_end:/registry/pods0; response_count:0; response_revision:15782; }","duration":"131.2685ms","start":"2023-01-22T18:29:32.054Z","end":"2023-01-22T18:29:32.185Z","steps":["trace[56263645] 'count revisions from in-memory index tree'  (duration: 131.1176ms)"],"step_count":1}
{"level":"info","ts":"2023-01-22T18:29:34.487Z","caller":"osutil/interrupt_unix.go:64","msg":"received signal; shutting down","signal":"terminated"}
{"level":"info","ts":"2023-01-22T18:29:35.053Z","caller":"embed/etcd.go:368","msg":"closing etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}
{"level":"info","ts":"2023-01-22T18:29:35.156Z","caller":"traceutil/trace.go:171","msg":"trace[537031863] linearizableReadLoop","detail":"{readStateIndex:20145; appliedIndex:20145; }","duration":"141.8478ms","start":"2023-01-22T18:29:35.014Z","end":"2023-01-22T18:29:35.156Z","steps":["trace[537031863] 'read index received'  (duration: 141.8402ms)","trace[537031863] 'applied index is now lower than readState.Index'  (duration: 6.5¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:29:35.531Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"516.8981ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:420"}
{"level":"info","ts":"2023-01-22T18:29:35.531Z","caller":"traceutil/trace.go:171","msg":"trace[1030186993] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:15784; }","duration":"516.9971ms","start":"2023-01-22T18:29:35.014Z","end":"2023-01-22T18:29:35.531Z","steps":["trace[1030186993] 'agreement among raft nodes before linearized reading'  (duration: 141.9586ms)","trace[1030186993] 'range keys from in-memory index tree'  (duration: 374.9082ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-22T18:29:35.532Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-22T18:29:35.014Z","time spent":"517.0664ms","remote":"127.0.0.1:59162","response type":"/etcdserverpb.KV/Range","request count":0,"request size":49,"response count":1,"response size":444,"request content":"key:\"/registry/services/endpoints/default/kubernetes\" "}
WARNING: 2023/01/22 18:29:36 [core] grpc: addrConn.createTransport failed to connect to {127.0.0.1:2379 127.0.0.1:2379 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused". Reconnecting...
WARNING: 2023/01/22 18:29:36 [core] grpc: addrConn.createTransport failed to connect to {192.168.49.2:2379 192.168.49.2:2379 <nil> 0 <nil>}. Err: connection error: desc = "transport: Error while dialing dial tcp 192.168.49.2:2379: connect: connection refused". Reconnecting...
{"level":"info","ts":"2023-01-22T18:29:36.945Z","caller":"etcdserver/server.go:1453","msg":"skipped leadership transfer for single voting member cluster","local-member-id":"aec36adc501070cc","current-leader-member-id":"aec36adc501070cc"}
{"level":"info","ts":"2023-01-22T18:29:38.029Z","caller":"embed/etcd.go:563","msg":"stopping serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-01-22T18:29:38.030Z","caller":"embed/etcd.go:568","msg":"stopped serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2023-01-22T18:29:38.030Z","caller":"embed/etcd.go:370","msg":"closed etcd server","name":"minikube","data-dir":"/var/lib/minikube/etcd","advertise-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"]}

* 
* ==> etcd [bde099f4f903] <==
* {"level":"info","ts":"2023-01-24T16:40:41.528Z","caller":"traceutil/trace.go:171","msg":"trace[885369901] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16420; }","duration":"136.6966ms","start":"2023-01-24T16:40:41.391Z","end":"2023-01-24T16:40:41.528Z","steps":["trace[885369901] 'range keys from in-memory index tree'  (duration: 136.4644ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:40:41.761Z","caller":"traceutil/trace.go:171","msg":"trace[1350973227] transaction","detail":"{read_only:false; response_revision:16422; number_of_response:1; }","duration":"169.0973ms","start":"2023-01-24T16:40:41.592Z","end":"2023-01-24T16:40:41.761Z","steps":["trace[1350973227] 'process raft request'  (duration: 127.1515ms)","trace[1350973227] 'compare'  (duration: 41.8529ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:40:42.533Z","caller":"traceutil/trace.go:171","msg":"trace[60832152] linearizableReadLoop","detail":"{readStateIndex:20916; appliedIndex:20916; }","duration":"152.1209ms","start":"2023-01-24T16:40:42.380Z","end":"2023-01-24T16:40:42.533Z","steps":["trace[60832152] 'read index received'  (duration: 152.1132ms)","trace[60832152] 'applied index is now lower than readState.Index'  (duration: 6.7¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:40:42.674Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"293.7834ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:40:42.674Z","caller":"traceutil/trace.go:171","msg":"trace[561302327] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16424; }","duration":"293.8812ms","start":"2023-01-24T16:40:42.380Z","end":"2023-01-24T16:40:42.674Z","steps":["trace[561302327] 'agreement among raft nodes before linearized reading'  (duration: 152.2553ms)","trace[561302327] 'range keys from in-memory index tree'  (duration: 141.51ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:40:42.674Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"141.6689ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018644457937152 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/endpointslices/ingress-nginx/ingress-nginx-controller-admission-xcwl2\" mod_revision:16409 > success:<request_put:<key:\"/registry/endpointslices/ingress-nginx/ingress-nginx-controller-admission-xcwl2\" value_size:1241 >> failure:<request_range:<key:\"/registry/endpointslices/ingress-nginx/ingress-nginx-controller-admission-xcwl2\" > >>","response":"size:18"}
{"level":"info","ts":"2023-01-24T16:40:42.674Z","caller":"traceutil/trace.go:171","msg":"trace[67464928] transaction","detail":"{read_only:false; response_revision:16425; number_of_response:1; }","duration":"197.4909ms","start":"2023-01-24T16:40:42.477Z","end":"2023-01-24T16:40:42.674Z","steps":["trace[67464928] 'process raft request'  (duration: 55.6534ms)","trace[67464928] 'compare'  (duration: 141.4717ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:40:42.675Z","caller":"traceutil/trace.go:171","msg":"trace[504011032] transaction","detail":"{read_only:false; response_revision:16426; number_of_response:1; }","duration":"139.4858ms","start":"2023-01-24T16:40:42.535Z","end":"2023-01-24T16:40:42.675Z","steps":["trace[504011032] 'process raft request'  (duration: 139.1789ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:40:42.675Z","caller":"traceutil/trace.go:171","msg":"trace[1989264420] transaction","detail":"{read_only:false; response_revision:16427; number_of_response:1; }","duration":"129.6866ms","start":"2023-01-24T16:40:42.545Z","end":"2023-01-24T16:40:42.675Z","steps":["trace[1989264420] 'process raft request'  (duration: 129.5381ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:40:42.675Z","caller":"traceutil/trace.go:171","msg":"trace[1587225228] linearizableReadLoop","detail":"{readStateIndex:20919; appliedIndex:20916; }","duration":"128.6914ms","start":"2023-01-24T16:40:42.546Z","end":"2023-01-24T16:40:42.675Z","steps":["trace[1587225228] 'read index received'  (duration: 77.6274ms)","trace[1587225228] 'applied index is now lower than readState.Index'  (duration: 51.0631ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:40:42.675Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"128.8129ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1111"}
{"level":"info","ts":"2023-01-24T16:40:42.675Z","caller":"traceutil/trace.go:171","msg":"trace[1898380033] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:16428; }","duration":"128.8466ms","start":"2023-01-24T16:40:42.546Z","end":"2023-01-24T16:40:42.675Z","steps":["trace[1898380033] 'agreement among raft nodes before linearized reading'  (duration: 128.7667ms)"],"step_count":1}
{"level":"warn","ts":"2023-01-24T16:40:43.274Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"486.7712ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/configmaps/ingress-nginx/ingress-controller-leader\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:40:43.274Z","caller":"traceutil/trace.go:171","msg":"trace[1182735948] range","detail":"{range_begin:/registry/configmaps/ingress-nginx/ingress-controller-leader; range_end:; response_count:0; response_revision:16429; }","duration":"486.8655ms","start":"2023-01-24T16:40:42.788Z","end":"2023-01-24T16:40:43.274Z","steps":["trace[1182735948] 'range keys from in-memory index tree'  (duration: 483.9301ms)"],"step_count":1}
{"level":"warn","ts":"2023-01-24T16:40:43.274Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"446.2385ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018644457937161 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9.173d4c38b12a0488\" mod_revision:0 > success:<request_put:<key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9.173d4c38b12a0488\" value_size:627 lease:8128018644457936878 >> failure:<>>","response":"size:18"}
{"level":"warn","ts":"2023-01-24T16:40:43.274Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-24T16:40:42.788Z","time spent":"486.9322ms","remote":"127.0.0.1:33382","response type":"/etcdserverpb.KV/Range","request count":0,"request size":62,"response count":0,"response size":30,"request content":"key:\"/registry/configmaps/ingress-nginx/ingress-controller-leader\" "}
{"level":"info","ts":"2023-01-24T16:40:43.275Z","caller":"traceutil/trace.go:171","msg":"trace[159397326] transaction","detail":"{read_only:false; response_revision:16430; number_of_response:1; }","duration":"446.5502ms","start":"2023-01-24T16:40:42.828Z","end":"2023-01-24T16:40:43.274Z","steps":["trace[159397326] 'compare'  (duration: 446.1039ms)"],"step_count":1}
{"level":"warn","ts":"2023-01-24T16:40:43.275Z","caller":"v3rpc/interceptor.go:197","msg":"request stats","start time":"2023-01-24T16:40:42.828Z","time spent":"446.6346ms","remote":"127.0.0.1:33366","response type":"/etcdserverpb.KV/Txn","request count":1,"request size":734,"response count":0,"response size":42,"request content":"compare:<target:MOD key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9.173d4c38b12a0488\" mod_revision:0 > success:<request_put:<key:\"/registry/events/ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9.173d4c38b12a0488\" value_size:627 lease:8128018644457936878 >> failure:<>"}
{"level":"warn","ts":"2023-01-24T16:40:43.545Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"153.6701ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:40:43.545Z","caller":"traceutil/trace.go:171","msg":"trace[222454042] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16432; }","duration":"153.7619ms","start":"2023-01-24T16:40:43.391Z","end":"2023-01-24T16:40:43.545Z","steps":["trace[222454042] 'range keys from in-memory index tree'  (duration: 153.6083ms)"],"step_count":1}
{"level":"warn","ts":"2023-01-24T16:40:48.821Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"106.0069ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:421"}
{"level":"info","ts":"2023-01-24T16:40:48.822Z","caller":"traceutil/trace.go:171","msg":"trace[1992828788] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:16435; }","duration":"106.2844ms","start":"2023-01-24T16:40:48.715Z","end":"2023-01-24T16:40:48.822Z","steps":["trace[1992828788] 'agreement among raft nodes before linearized reading'  (duration: 25.3755ms)","trace[1992828788] 'range keys from in-memory index tree'  (duration: 80.5958ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:40:52.050Z","caller":"traceutil/trace.go:171","msg":"trace[1311250496] transaction","detail":"{read_only:false; response_revision:16445; number_of_response:1; }","duration":"152.9334ms","start":"2023-01-24T16:40:51.897Z","end":"2023-01-24T16:40:52.050Z","steps":["trace[1311250496] 'process raft request'  (duration: 152.9032ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:40:52.050Z","caller":"traceutil/trace.go:171","msg":"trace[1843003160] transaction","detail":"{read_only:false; response_revision:16441; number_of_response:1; }","duration":"154.8395ms","start":"2023-01-24T16:40:51.895Z","end":"2023-01-24T16:40:52.050Z","steps":["trace[1843003160] 'process raft request'  (duration: 95.5627ms)","trace[1843003160] 'compare'  (duration: 59.0041ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:40:52.050Z","caller":"traceutil/trace.go:171","msg":"trace[404339753] transaction","detail":"{read_only:false; response_revision:16444; number_of_response:1; }","duration":"154.8623ms","start":"2023-01-24T16:40:51.896Z","end":"2023-01-24T16:40:52.050Z","steps":["trace[404339753] 'process raft request'  (duration: 154.6136ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:40:52.050Z","caller":"traceutil/trace.go:171","msg":"trace[1452761163] transaction","detail":"{read_only:false; response_revision:16442; number_of_response:1; }","duration":"154.6869ms","start":"2023-01-24T16:40:51.896Z","end":"2023-01-24T16:40:52.050Z","steps":["trace[1452761163] 'process raft request'  (duration: 154.5876ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:40:52.050Z","caller":"traceutil/trace.go:171","msg":"trace[2143961001] transaction","detail":"{read_only:false; response_revision:16443; number_of_response:1; }","duration":"154.934ms","start":"2023-01-24T16:40:51.896Z","end":"2023-01-24T16:40:52.050Z","steps":["trace[2143961001] 'process raft request'  (duration: 154.6054ms)"],"step_count":1}
{"level":"warn","ts":"2023-01-24T16:41:08.844Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"127.2091ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018644457937328 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:16451 > success:<request_put:<key:\"/registry/masterleases/192.168.49.2\" value_size:65 lease:8128018644457937326 >> failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >>","response":"size:18"}
{"level":"info","ts":"2023-01-24T16:41:08.844Z","caller":"traceutil/trace.go:171","msg":"trace[1819097220] transaction","detail":"{read_only:false; response_revision:16460; number_of_response:1; }","duration":"149.9667ms","start":"2023-01-24T16:41:08.694Z","end":"2023-01-24T16:41:08.844Z","steps":["trace[1819097220] 'process raft request'  (duration: 22.5466ms)","trace[1819097220] 'compare'  (duration: 127.1357ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:41:18.799Z","caller":"traceutil/trace.go:171","msg":"trace[76906805] transaction","detail":"{read_only:false; response_revision:16468; number_of_response:1; }","duration":"102.5573ms","start":"2023-01-24T16:41:18.696Z","end":"2023-01-24T16:41:18.799Z","steps":["trace[76906805] 'process raft request'  (duration: 21.4145ms)","trace[76906805] 'compare'  (duration: 81.0438ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:41:29.132Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"113.2972ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath\" ","response":"range_response_count:1 size:1111"}
{"level":"info","ts":"2023-01-24T16:41:29.132Z","caller":"traceutil/trace.go:171","msg":"trace[738752880] range","detail":"{range_begin:/registry/services/endpoints/kube-system/k8s.io-minikube-hostpath; range_end:; response_count:1; response_revision:16477; }","duration":"113.3801ms","start":"2023-01-24T16:41:29.019Z","end":"2023-01-24T16:41:29.132Z","steps":["trace[738752880] 'range keys from in-memory index tree'  (duration: 113.1658ms)"],"step_count":1}
{"level":"info","ts":"2023-01-24T16:41:31.676Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":16103}
{"level":"info","ts":"2023-01-24T16:41:31.695Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":16103,"took":"853.2¬µs"}
{"level":"warn","ts":"2023-01-24T16:41:32.542Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"161.3886ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:41:32.542Z","caller":"traceutil/trace.go:171","msg":"trace[74248684] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16481; }","duration":"161.4836ms","start":"2023-01-24T16:41:32.381Z","end":"2023-01-24T16:41:32.542Z","steps":["trace[74248684] 'agreement among raft nodes before linearized reading'  (duration: 32.1805ms)","trace[74248684] 'range keys from in-memory index tree'  (duration: 129.1901ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:41:58.862Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"127.1206ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:421"}
{"level":"info","ts":"2023-01-24T16:41:58.862Z","caller":"traceutil/trace.go:171","msg":"trace[1161939351] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:16503; }","duration":"127.2294ms","start":"2023-01-24T16:41:58.735Z","end":"2023-01-24T16:41:58.862Z","steps":["trace[1161939351] 'agreement among raft nodes before linearized reading'  (duration: 93.0051ms)","trace[1161939351] 'range keys from in-memory index tree'  (duration: 34.0641ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:42:01.504Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"123.6391ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:42:01.504Z","caller":"traceutil/trace.go:171","msg":"trace[1340122052] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16505; }","duration":"123.7298ms","start":"2023-01-24T16:42:01.380Z","end":"2023-01-24T16:42:01.504Z","steps":["trace[1340122052] 'range keys from in-memory index tree'  (duration: 120.8806ms)"],"step_count":1}
{"level":"warn","ts":"2023-01-24T16:42:07.529Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"137.8136ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:42:07.529Z","caller":"traceutil/trace.go:171","msg":"trace[1192051212] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16510; }","duration":"137.9088ms","start":"2023-01-24T16:42:07.392Z","end":"2023-01-24T16:42:07.529Z","steps":["trace[1192051212] 'agreement among raft nodes before linearized reading'  (duration: 94.0817ms)","trace[1192051212] 'range keys from in-memory index tree'  (duration: 43.7131ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:42:08.838Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"102.2767ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:421"}
{"level":"info","ts":"2023-01-24T16:42:08.838Z","caller":"traceutil/trace.go:171","msg":"trace[77479843] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:16511; }","duration":"102.4228ms","start":"2023-01-24T16:42:08.736Z","end":"2023-01-24T16:42:08.838Z","steps":["trace[77479843] 'agreement among raft nodes before linearized reading'  (duration: 21.1487ms)","trace[77479843] 'range keys from in-memory index tree'  (duration: 81.0974ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:42:18.840Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"106.5895ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018644457937681 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/masterleases/192.168.49.2\" mod_revision:16511 > success:<request_put:<key:\"/registry/masterleases/192.168.49.2\" value_size:65 lease:8128018644457937679 >> failure:<request_range:<key:\"/registry/masterleases/192.168.49.2\" > >>","response":"size:18"}
{"level":"info","ts":"2023-01-24T16:42:18.840Z","caller":"traceutil/trace.go:171","msg":"trace[983382460] transaction","detail":"{read_only:false; response_revision:16519; number_of_response:1; }","duration":"142.5068ms","start":"2023-01-24T16:42:18.697Z","end":"2023-01-24T16:42:18.840Z","steps":["trace[983382460] 'process raft request'  (duration: 35.6408ms)","trace[983382460] 'compare'  (duration: 106.4364ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:42:21.648Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"208.1481ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/health\" ","response":"range_response_count:0 size:6"}
{"level":"info","ts":"2023-01-24T16:42:21.648Z","caller":"traceutil/trace.go:171","msg":"trace[348850762] range","detail":"{range_begin:/registry/health; range_end:; response_count:0; response_revision:16522; }","duration":"208.2476ms","start":"2023-01-24T16:42:21.440Z","end":"2023-01-24T16:42:21.648Z","steps":["trace[348850762] 'agreement among raft nodes before linearized reading'  (duration: 95.7675ms)","trace[348850762] 'range keys from in-memory index tree'  (duration: 112.3639ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:42:33.785Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"172.8923ms","expected-duration":"100ms","prefix":"","request":"header:<ID:8128018644457937757 username:\"kube-apiserver-etcd-client\" auth_revision:1 > txn:<compare:<target:MOD key:\"/registry/leases/kube-node-lease/minikube\" mod_revision:16523 > success:<request_put:<key:\"/registry/leases/kube-node-lease/minikube\" value_size:472 >> failure:<request_range:<key:\"/registry/leases/kube-node-lease/minikube\" > >>","response":"size:18"}
{"level":"info","ts":"2023-01-24T16:42:33.785Z","caller":"traceutil/trace.go:171","msg":"trace[423052549] transaction","detail":"{read_only:false; response_revision:16532; number_of_response:1; }","duration":"183.3374ms","start":"2023-01-24T16:42:33.602Z","end":"2023-01-24T16:42:33.785Z","steps":["trace[423052549] 'process raft request'  (duration: 10.2287ms)","trace[423052549] 'compare'  (duration: 172.7076ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:42:38.824Z","caller":"traceutil/trace.go:171","msg":"trace[555102104] transaction","detail":"{read_only:false; response_revision:16536; number_of_response:1; }","duration":"125.2339ms","start":"2023-01-24T16:42:38.699Z","end":"2023-01-24T16:42:38.824Z","steps":["trace[555102104] 'process raft request'  (duration: 46.7883ms)","trace[555102104] 'compare'  (duration: 78.2362ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:42:39.669Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"147.3091ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/validatingwebhookconfigurations/\" range_end:\"/registry/validatingwebhookconfigurations0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2023-01-24T16:42:39.669Z","caller":"traceutil/trace.go:171","msg":"trace[1113927679] range","detail":"{range_begin:/registry/validatingwebhookconfigurations/; range_end:/registry/validatingwebhookconfigurations0; response_count:0; response_revision:16537; }","duration":"147.4128ms","start":"2023-01-24T16:42:39.522Z","end":"2023-01-24T16:42:39.669Z","steps":["trace[1113927679] 'agreement among raft nodes before linearized reading'  (duration: 65.8334ms)","trace[1113927679] 'count revisions from in-memory index tree'  (duration: 81.459ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:42:48.814Z","caller":"traceutil/trace.go:171","msg":"trace[498813374] transaction","detail":"{read_only:false; response_revision:16544; number_of_response:1; }","duration":"116.097ms","start":"2023-01-24T16:42:48.698Z","end":"2023-01-24T16:42:48.814Z","steps":["trace[498813374] 'process raft request'  (duration: 40.6306ms)","trace[498813374] 'compare'  (duration: 74.5591ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:43:01.793Z","caller":"traceutil/trace.go:171","msg":"trace[1768232165] linearizableReadLoop","detail":"{readStateIndex:21076; appliedIndex:21076; }","duration":"122.4191ms","start":"2023-01-24T16:43:01.670Z","end":"2023-01-24T16:43:01.793Z","steps":["trace[1768232165] 'read index received'  (duration: 122.413ms)","trace[1768232165] 'applied index is now lower than readState.Index'  (duration: 5.3¬µs)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:43:01.836Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"165.1837ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/daemonsets/\" range_end:\"/registry/daemonsets0\" count_only:true ","response":"range_response_count:0 size:8"}
{"level":"info","ts":"2023-01-24T16:43:01.836Z","caller":"traceutil/trace.go:171","msg":"trace[1104155233] range","detail":"{range_begin:/registry/daemonsets/; range_end:/registry/daemonsets0; response_count:0; response_revision:16555; }","duration":"165.2834ms","start":"2023-01-24T16:43:01.670Z","end":"2023-01-24T16:43:01.836Z","steps":["trace[1104155233] 'agreement among raft nodes before linearized reading'  (duration: 122.4957ms)","trace[1104155233] 'count revisions from in-memory index tree'  (duration: 42.6702ms)"],"step_count":2}
{"level":"info","ts":"2023-01-24T16:43:08.824Z","caller":"traceutil/trace.go:171","msg":"trace[1403259022] transaction","detail":"{read_only:false; response_revision:16561; number_of_response:1; }","duration":"118.5062ms","start":"2023-01-24T16:43:08.706Z","end":"2023-01-24T16:43:08.824Z","steps":["trace[1403259022] 'process raft request'  (duration: 51.9532ms)","trace[1403259022] 'compare'  (duration: 66.2662ms)"],"step_count":2}
{"level":"warn","ts":"2023-01-24T16:43:38.832Z","caller":"etcdserver/util.go:166","msg":"apply request took too long","took":"102.3758ms","expected-duration":"100ms","prefix":"read-only range ","request":"key:\"/registry/services/endpoints/default/kubernetes\" ","response":"range_response_count:1 size:421"}
{"level":"info","ts":"2023-01-24T16:43:38.832Z","caller":"traceutil/trace.go:171","msg":"trace[72428801] range","detail":"{range_begin:/registry/services/endpoints/default/kubernetes; range_end:; response_count:1; response_revision:16586; }","duration":"102.485ms","start":"2023-01-24T16:43:38.729Z","end":"2023-01-24T16:43:38.832Z","steps":["trace[72428801] 'agreement among raft nodes before linearized reading'  (duration: 21.777ms)","trace[72428801] 'range keys from in-memory index tree'  (duration: 80.5863ms)"],"step_count":2}

* 
* ==> kernel <==
*  16:43:48 up  1:15,  0 users,  load average: 0.64, 1.58, 1.28
Linux minikube 4.19.128-microsoft-standard #1 SMP Tue Jun 23 12:58:10 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.5 LTS"

* 
* ==> kube-apiserver [0860f5644563] <==
* I0124 16:39:34.159752       1 trace.go:205] Trace[1859576573]: "Get" url:/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations/ingress-nginx-admission,user-agent:kubectl/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:8451aa7a-8609-4725-b304-6bbf90d3db5b,client:127.0.0.1,accept:application/json,protocol:HTTP/2.0 (24-Jan-2023 16:39:32.179) (total time: 1980ms):
Trace[1859576573]: ---"About to write a response" 1980ms (16:39:34.159)
Trace[1859576573]: [1.9804422s] [1.9804422s] END
I0124 16:39:34.163263       1 trace.go:205] Trace[186279479]: "GuaranteedUpdate etcd3" audit-id:6dd4144e-aaef-4e31-851b-7db800071e52,key:/replicasets/ingress-nginx/ingress-nginx-controller-8574b6d7c9,type:*apps.ReplicaSet (24-Jan-2023 16:39:33.111) (total time: 1051ms):
Trace[186279479]: ---"Txn call finished" err:<nil> 1045ms (16:39:34.159)
Trace[186279479]: [1.0515397s] [1.0515397s] END
I0124 16:39:34.163435       1 trace.go:205] Trace[1167922162]: "Update" url:/apis/apps/v1/namespaces/ingress-nginx/replicasets/ingress-nginx-controller-8574b6d7c9/status,user-agent:kube-controller-manager/v1.25.3 (linux/amd64) kubernetes/434bfd8/system:serviceaccount:kube-system:replicaset-controller,audit-id:6dd4144e-aaef-4e31-851b-7db800071e52,client:192.168.49.2,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:33.111) (total time: 1051ms):
Trace[1167922162]: ---"Write to database call finished" len:4848,err:Operation cannot be fulfilled on replicasets.apps "ingress-nginx-controller-8574b6d7c9": the object has been modified; please apply your changes to the latest version and try again 1051ms (16:39:34.163)
Trace[1167922162]: [1.051949s] [1.051949s] END
I0124 16:39:34.401701       1 trace.go:205] Trace[1982727688]: "Get" url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,audit-id:6478bb6b-174d-4bbd-80d2-356d11b3f0fa,client:192.168.49.2,accept:application/json, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:33.327) (total time: 1074ms):
Trace[1982727688]: ---"About to write a response" 1074ms (16:39:34.401)
Trace[1982727688]: [1.0743787s] [1.0743787s] END
I0124 16:39:34.869005       1 trace.go:205] Trace[1490139625]: "List(recursive=true) etcd3" audit-id:,key:/masterleases/,resourceVersion:0,resourceVersionMatch:NotOlderThan,limit:0,continue: (24-Jan-2023 16:39:34.160) (total time: 708ms):
Trace[1490139625]: [708.7644ms] [708.7644ms] END
I0124 16:39:34.869307       1 trace.go:205] Trace[1779379252]: "Get" url:/apis/apps/v1/namespaces/ingress-nginx/replicasets/ingress-nginx-controller-8574b6d7c9,user-agent:kube-controller-manager/v1.25.3 (linux/amd64) kubernetes/434bfd8/system:serviceaccount:kube-system:replicaset-controller,audit-id:dd0a8246-fa8f-48b2-a4c7-f22f67940f85,client:192.168.49.2,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:34.164) (total time: 704ms):
Trace[1779379252]: ---"About to write a response" 704ms (16:39:34.869)
Trace[1779379252]: [704.4124ms] [704.4124ms] END
I0124 16:39:35.709584       1 trace.go:205] Trace[1691845716]: "Get" url:/apis/discovery.k8s.io/v1/namespaces/default/endpointslices/kubernetes,user-agent:kube-apiserver/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:4ee152b4-d63c-41ac-b68e-0c288e8ab11d,client:127.0.0.1,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:34.869) (total time: 839ms):
Trace[1691845716]: ---"About to write a response" 839ms (16:39:35.709)
Trace[1691845716]: [839.7579ms] [839.7579ms] END
I0124 16:39:35.709937       1 trace.go:205] Trace[1141269780]: "GuaranteedUpdate etcd3" audit-id:514a2a19-7dcf-4ed8-ba8b-8f29bbe04555,key:/replicasets/ingress-nginx/ingress-nginx-controller-8574b6d7c9,type:*apps.ReplicaSet (24-Jan-2023 16:39:34.871) (total time: 838ms):
Trace[1141269780]: ---"Txn call finished" err:<nil> 835ms (16:39:35.709)
Trace[1141269780]: [838.3054ms] [838.3054ms] END
I0124 16:39:35.710149       1 trace.go:205] Trace[1104724662]: "Get" url:/api/v1/namespaces/kube-system,user-agent:kube-apiserver/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:9ea5923d-ebcb-4ad9-b61d-703c3a3a2845,client:127.0.0.1,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:35.031) (total time: 679ms):
Trace[1104724662]: ---"About to write a response" 678ms (16:39:35.710)
Trace[1104724662]: [679.044ms] [679.044ms] END
I0124 16:39:35.710166       1 trace.go:205] Trace[882834805]: "Update" url:/apis/apps/v1/namespaces/ingress-nginx/replicasets/ingress-nginx-controller-8574b6d7c9/status,user-agent:kube-controller-manager/v1.25.3 (linux/amd64) kubernetes/434bfd8/system:serviceaccount:kube-system:replicaset-controller,audit-id:514a2a19-7dcf-4ed8-ba8b-8f29bbe04555,client:192.168.49.2,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:34.871) (total time: 838ms):
Trace[882834805]: ---"Write to database call finished" len:4848,err:<nil> 838ms (16:39:35.709)
Trace[882834805]: [838.9166ms] [838.9166ms] END
I0124 16:39:36.251022       1 trace.go:205] Trace[1327538065]: "Get" url:/api/v1/namespaces/ingress-nginx,user-agent:kubectl/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:212fd4bb-99ff-4e4d-81cd-650877de8a17,client:127.0.0.1,accept:application/json,protocol:HTTP/2.0 (24-Jan-2023 16:39:35.496) (total time: 754ms):
Trace[1327538065]: ---"About to write a response" 754ms (16:39:36.250)
Trace[1327538065]: [754.4375ms] [754.4375ms] END
I0124 16:39:36.251057       1 trace.go:205] Trace[133084328]: "GuaranteedUpdate etcd3" audit-id:27a98ca6-2e87-4343-b0c2-f5fe1ea0f46a,key:/deployments/ingress-nginx/ingress-nginx-controller,type:*apps.Deployment (24-Jan-2023 16:39:35.711) (total time: 539ms):
Trace[133084328]: ---"About to Encode" 178ms (16:39:35.890)
Trace[133084328]: ---"Txn call finished" err:<nil> 360ms (16:39:36.250)
Trace[133084328]: [539.425ms] [539.425ms] END
I0124 16:39:36.251087       1 trace.go:205] Trace[2099216823]: "Get" url:/api/v1/namespaces/kube-public,user-agent:kube-apiserver/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:edcddc4e-d4ce-40de-9bd0-e937dd3875b3,client:127.0.0.1,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:35.710) (total time: 540ms):
Trace[2099216823]: ---"About to write a response" 540ms (16:39:36.251)
Trace[2099216823]: [540.3168ms] [540.3168ms] END
I0124 16:39:36.251310       1 trace.go:205] Trace[404912508]: "Update" url:/apis/apps/v1/namespaces/ingress-nginx/deployments/ingress-nginx-controller/status,user-agent:kube-controller-manager/v1.25.3 (linux/amd64) kubernetes/434bfd8/system:serviceaccount:kube-system:deployment-controller,audit-id:27a98ca6-2e87-4343-b0c2-f5fe1ea0f46a,client:192.168.49.2,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:35.711) (total time: 539ms):
Trace[404912508]: ---"Write to database call finished" len:8431,err:<nil> 539ms (16:39:36.251)
Trace[404912508]: [539.9641ms] [539.9641ms] END
I0124 16:39:43.705831       1 trace.go:205] Trace[856060667]: "Get" url:/apis/rbac.authorization.k8s.io/v1/namespaces/ingress-nginx/roles/ingress-nginx,user-agent:kubectl/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:93eb5edd-4c72-4e15-ba8c-dfe7a9e3299e,client:127.0.0.1,accept:application/json,protocol:HTTP/2.0 (24-Jan-2023 16:39:42.989) (total time: 716ms):
Trace[856060667]: ---"About to write a response" 715ms (16:39:43.705)
Trace[856060667]: [716.0732ms] [716.0732ms] END
I0124 16:39:59.553555       1 trace.go:205] Trace[1059245825]: "Get" url:/api/v1/namespaces/default,user-agent:kube-apiserver/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:d662318b-b17d-4598-b6ab-3541a061332f,client:127.0.0.1,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:39:58.642) (total time: 911ms):
Trace[1059245825]: ---"About to write a response" 911ms (16:39:59.553)
Trace[1059245825]: [911.4645ms] [911.4645ms] END
I0124 16:40:29.496888       1 trace.go:205] Trace[961806044]: "GuaranteedUpdate etcd3" audit-id:,key:/masterleases/192.168.49.2,type:*v1.Endpoints (24-Jan-2023 16:40:28.737) (total time: 759ms):
Trace[961806044]: ---"Txn call finished" err:<nil> 757ms (16:40:29.496)
Trace[961806044]: [759.3875ms] [759.3875ms] END
I0124 16:40:29.497037       1 trace.go:205] Trace[591529987]: "Get" url:/api/v1/namespaces/kube-system/endpoints/k8s.io-minikube-hostpath,user-agent:storage-provisioner/v0.0.0 (linux/amd64) kubernetes/$Format,audit-id:0885d321-0719-44ec-9a6f-b7123425d52f,client:192.168.49.2,accept:application/json, */*,protocol:HTTP/2.0 (24-Jan-2023 16:40:28.994) (total time: 502ms):
Trace[591529987]: ---"About to write a response" 502ms (16:40:29.496)
Trace[591529987]: [502.7572ms] [502.7572ms] END
I0124 16:40:30.346084       1 trace.go:205] Trace[1038711623]: "Get" url:/api/v1/namespaces/default/endpoints/kubernetes,user-agent:kube-apiserver/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:d205ba18-566f-4517-bba3-cd170fa2fd7d,client:127.0.0.1,accept:application/vnd.kubernetes.protobuf, */*,protocol:HTTP/2.0 (24-Jan-2023 16:40:29.497) (total time: 848ms):
Trace[1038711623]: ---"About to write a response" 848ms (16:40:30.345)
Trace[1038711623]: [848.6192ms] [848.6192ms] END
I0124 16:40:35.417395       1 trace.go:205] Trace[1746008677]: "Delete" url:/api/v1/namespaces/ingress-nginx/pods/ingress-nginx-controller-8574b6d7c9-9clxt,user-agent:kubelet/v1.25.3 (linux/amd64) kubernetes/434bfd8,audit-id:b90db303-168b-4272-9ea7-a0e272a0890d,client:192.168.49.2,accept:application/vnd.kubernetes.protobuf,application/json,protocol:HTTP/2.0 (24-Jan-2023 16:40:34.703) (total time: 713ms):
Trace[1746008677]: ---"Object deleted from database" 713ms (16:40:35.416)
Trace[1746008677]: [713.8299ms] [713.8299ms] END

* 
* ==> kube-apiserver [08d7c9bdcf83] <==
*   "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:41.956304       1 logging.go:59] [core] [Channel #31 SubChannel #32] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:41.972321       1 logging.go:59] [core] [Channel #76 SubChannel #77] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:42.006771       1 logging.go:59] [core] [Channel #73 SubChannel #74] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:42.050309       1 logging.go:59] [core] [Channel #142 SubChannel #143] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:42.149214       1 logging.go:59] [core] [Channel #157 SubChannel #158] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:42.248805       1 logging.go:59] [core] [Channel #64 SubChannel #65] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"
W0122 18:29:42.297595       1 logging.go:59] [core] [Channel #28 SubChannel #29] grpc: addrConn.createTransport failed to connect to {
  "Addr": "127.0.0.1:2379",
  "ServerName": "127.0.0.1",
  "Attributes": null,
  "BalancerAttributes": null,
  "Type": 0,
  "Metadata": null
}. Err: connection error: desc = "transport: Error while dialing dial tcp 127.0.0.1:2379: connect: connection refused"

* 
* ==> kube-controller-manager [a2467760f941] <==
* I0124 16:31:52.650499       1 shared_informer.go:255] Waiting for caches to sync for garbage collector
I0124 16:31:52.655101       1 shared_informer.go:262] Caches are synced for HPA
I0124 16:31:52.661196       1 shared_informer.go:262] Caches are synced for attach detach
I0124 16:31:52.663787       1 shared_informer.go:262] Caches are synced for ReplicationController
I0124 16:31:52.670268       1 shared_informer.go:262] Caches are synced for resource quota
I0124 16:31:52.672542       1 shared_informer.go:262] Caches are synced for disruption
I0124 16:31:52.674965       1 shared_informer.go:262] Caches are synced for taint
I0124 16:31:52.675064       1 taint_manager.go:204] "Starting NoExecuteTaintManager"
I0124 16:31:52.675078       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
I0124 16:31:52.675134       1 taint_manager.go:209] "Sending events to api server"
W0124 16:31:52.675165       1 node_lifecycle_controller.go:1058] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0124 16:31:52.675226       1 node_lifecycle_controller.go:1259] Controller detected that zone  is now in state Normal.
I0124 16:31:52.675309       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0124 16:31:52.679517       1 shared_informer.go:262] Caches are synced for endpoint
W0124 16:31:52.688521       1 actual_state_of_world.go:541] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I0124 16:31:52.700855       1 shared_informer.go:262] Caches are synced for ephemeral
I0124 16:31:52.704182       1 shared_informer.go:262] Caches are synced for stateful set
I0124 16:31:52.704237       1 shared_informer.go:262] Caches are synced for PVC protection
I0124 16:31:52.706599       1 shared_informer.go:262] Caches are synced for deployment
I0124 16:31:52.709268       1 shared_informer.go:262] Caches are synced for ReplicaSet
I0124 16:31:52.712890       1 shared_informer.go:262] Caches are synced for endpoint_slice
I0124 16:31:52.712946       1 shared_informer.go:262] Caches are synced for TTL
I0124 16:31:52.715466       1 shared_informer.go:262] Caches are synced for persistent volume
I0124 16:31:52.718772       1 shared_informer.go:262] Caches are synced for daemon sets
I0124 16:31:52.722205       1 shared_informer.go:262] Caches are synced for GC
I0124 16:31:52.731589       1 shared_informer.go:262] Caches are synced for job
I0124 16:31:52.748615       1 shared_informer.go:262] Caches are synced for resource quota
I0124 16:31:53.050806       1 shared_informer.go:262] Caches are synced for garbage collector
I0124 16:31:53.148195       1 shared_informer.go:262] Caches are synced for garbage collector
I0124 16:31:53.148236       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0124 16:38:44.388008       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-controller" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set ingress-nginx-controller-8574b6d7c9 to 1"
I0124 16:38:44.398724       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:38:44.398761       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:38:44.835064       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:38:44.835250       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:38:44.904196       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-admission-patch" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-patch-s7qhr"
I0124 16:38:44.904234       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-admission-create" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-admission-create-w4rwl"
I0124 16:38:44.904197       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-controller-8574b6d7c9" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-controller-8574b6d7c9-9clxt"
I0124 16:38:45.129198       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:38:45.129239       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:38:45.745813       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:38:45.746037       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:38:46.267530       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:38:46.308674       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:39:10.245812       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:39:10.624021       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:39:15.353643       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:39:16.177415       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:39:16.642427       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:39:17.179803       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:39:17.179904       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-admission-patch" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="Completed" message="Job completed"
I0124 16:39:17.240183       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:39:17.240314       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-patch
I0124 16:39:17.526354       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:39:17.526478       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-admission-create" fieldPath="" kind="Job" apiVersion="batch/v1" type="Normal" reason="Completed" message="Job completed"
I0124 16:39:17.938623       1 job_controller.go:510] enqueueing job ingress-nginx/ingress-nginx-admission-create
I0124 16:39:26.603513       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-controller" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set ingress-nginx-controller-5959f988fd to 1"
I0124 16:39:27.993524       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-controller-5959f988fd" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: ingress-nginx-controller-5959f988fd-sr6q9"
I0124 16:39:29.038722       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-controller" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set ingress-nginx-controller-8574b6d7c9 to 0 from 1"
I0124 16:39:32.179910       1 event.go:294] "Event occurred" object="ingress-nginx/ingress-nginx-controller-8574b6d7c9" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: ingress-nginx-controller-8574b6d7c9-9clxt"

* 
* ==> kube-controller-manager [b3ae1c45726f] <==
* I0122 17:29:49.451157       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kubelet-client
I0122 17:29:49.475975       1 shared_informer.go:262] Caches are synced for crt configmap
I0122 17:29:49.476442       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kubelet-serving
I0122 17:29:49.476492       1 shared_informer.go:262] Caches are synced for bootstrap_signer
I0122 17:29:49.476539       1 shared_informer.go:262] Caches are synced for node
I0122 17:29:49.476585       1 shared_informer.go:262] Caches are synced for certificate-csrapproving
I0122 17:29:49.476625       1 shared_informer.go:262] Caches are synced for TTL
I0122 17:29:49.476606       1 range_allocator.go:166] Starting range CIDR allocator
I0122 17:29:49.476652       1 shared_informer.go:255] Waiting for caches to sync for cidrallocator
I0122 17:29:49.476662       1 shared_informer.go:262] Caches are synced for cidrallocator
I0122 17:29:49.476670       1 shared_informer.go:262] Caches are synced for expand
I0122 17:29:49.476712       1 shared_informer.go:262] Caches are synced for PV protection
I0122 17:29:49.476737       1 shared_informer.go:262] Caches are synced for service account
I0122 17:29:49.572646       1 shared_informer.go:262] Caches are synced for endpoint_slice_mirroring
I0122 17:29:49.572681       1 shared_informer.go:262] Caches are synced for namespace
I0122 17:29:49.572694       1 shared_informer.go:262] Caches are synced for cronjob
I0122 17:29:49.572758       1 shared_informer.go:255] Waiting for caches to sync for garbage collector
I0122 17:29:49.572927       1 shared_informer.go:262] Caches are synced for TTL after finished
I0122 17:29:49.619550       1 shared_informer.go:262] Caches are synced for ClusterRoleAggregator
I0122 17:29:49.648522       1 shared_informer.go:262] Caches are synced for endpoint
I0122 17:29:49.649279       1 shared_informer.go:262] Caches are synced for resource quota
I0122 17:29:49.657589       1 shared_informer.go:262] Caches are synced for job
I0122 17:29:49.658865       1 shared_informer.go:262] Caches are synced for PVC protection
I0122 17:29:49.660032       1 shared_informer.go:262] Caches are synced for ReplicaSet
I0122 17:29:49.692895       1 shared_informer.go:262] Caches are synced for resource quota
I0122 17:29:49.744235       1 shared_informer.go:262] Caches are synced for taint
I0122 17:29:49.744432       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
W0122 17:29:49.744621       1 node_lifecycle_controller.go:1058] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0122 17:29:49.744727       1 node_lifecycle_controller.go:1259] Controller detected that zone  is now in state Normal.
I0122 17:29:49.767415       1 shared_informer.go:262] Caches are synced for stateful set
I0122 17:29:49.767471       1 shared_informer.go:262] Caches are synced for endpoint_slice
I0122 17:29:49.767486       1 shared_informer.go:262] Caches are synced for ReplicationController
I0122 17:29:49.767510       1 shared_informer.go:262] Caches are synced for ephemeral
I0122 17:29:49.767549       1 shared_informer.go:262] Caches are synced for persistent volume
I0122 17:29:49.767724       1 shared_informer.go:262] Caches are synced for deployment
I0122 17:29:49.768117       1 shared_informer.go:262] Caches are synced for disruption
I0122 17:29:49.768148       1 shared_informer.go:262] Caches are synced for HPA
I0122 17:29:49.768213       1 taint_manager.go:204] "Starting NoExecuteTaintManager"
I0122 17:29:49.768299       1 taint_manager.go:209] "Sending events to api server"
I0122 17:29:49.768764       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0122 17:29:49.768814       1 shared_informer.go:262] Caches are synced for daemon sets
I0122 17:29:49.768833       1 shared_informer.go:262] Caches are synced for GC
I0122 17:29:49.801500       1 shared_informer.go:262] Caches are synced for attach detach
I0122 17:29:50.054285       1 shared_informer.go:262] Caches are synced for garbage collector
I0122 17:29:50.054324       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage
I0122 17:29:50.076994       1 shared_informer.go:262] Caches are synced for garbage collector
I0122 17:44:02.101713       1 event.go:294] "Event occurred" object="default/posts-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set posts-depl-577f4d78 to 1"
I0122 17:44:02.357205       1 event.go:294] "Event occurred" object="default/posts-depl-577f4d78" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: posts-depl-577f4d78-nk8jk"
I0122 17:44:17.261838       1 event.go:294] "Event occurred" object="default/posts-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set posts-depl-d947955dd to 0 from 1"
I0122 17:44:17.632320       1 event.go:294] "Event occurred" object="default/posts-depl-d947955dd" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: posts-depl-d947955dd-q9v59"
I0122 18:08:04.649655       1 event.go:294] "Event occurred" object="default/comments-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set comments-depl-554fddcdf8 to 1"
I0122 18:08:04.978786       1 event.go:294] "Event occurred" object="default/comments-depl-554fddcdf8" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: comments-depl-554fddcdf8-vcm8f"
I0122 18:08:06.149002       1 event.go:294] "Event occurred" object="default/moderation-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set moderation-depl-6ffdbb65d8 to 1"
I0122 18:08:06.153252       1 event.go:294] "Event occurred" object="default/moderation-depl-6ffdbb65d8" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: moderation-depl-6ffdbb65d8-phg47"
I0122 18:08:08.156353       1 event.go:294] "Event occurred" object="default/query-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set query-depl-7df9688c4d to 1"
I0122 18:08:08.457439       1 event.go:294] "Event occurred" object="default/query-depl-7df9688c4d" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: query-depl-7df9688c4d-9p272"
I0122 18:19:27.902760       1 event.go:294] "Event occurred" object="default/event-bus-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set event-bus-depl-7dccf69b77 to 1"
I0122 18:19:28.349524       1 event.go:294] "Event occurred" object="default/event-bus-depl-7dccf69b77" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: event-bus-depl-7dccf69b77-5srzh"
I0122 18:19:41.767819       1 event.go:294] "Event occurred" object="default/event-bus-depl" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled down replica set event-bus-depl-7d5f455fcf to 0 from 1"
I0122 18:19:42.074586       1 event.go:294] "Event occurred" object="default/event-bus-depl-7d5f455fcf" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulDelete" message="Deleted pod: event-bus-depl-7d5f455fcf-czdxh"

* 
* ==> kube-proxy [011033b14299] <==
* 	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:38:50.125997       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:39:20.153222       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:39:20.153263       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:39:25.397878       1 service_health.go:187] "Healthcheck closed" err="accept tcp [::]:32606: use of closed network connection" service="ingress-nginx/ingress-nginx-controller"
E0124 16:39:50.190231       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:39:50.190293       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:40:20.218926       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:40:20.218965       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:40:50.245584       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:40:50.245626       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:41:20.270477       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:41:20.270515       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:41:50.298544       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:41:50.298567       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:42:20.340780       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:42:20.340836       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:42:50.371460       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:42:50.371495       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0124 16:43:20.400538       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0124 16:43:20.400579       1 proxier.go:855] "Sync failed" retryingTime="30s"

* 
* ==> kube-proxy [7a1683e959d1] <==
* E0122 18:24:53.085008       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:24:53.085044       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:25:23.142699       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:25:23.142759       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:25:53.176265       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:25:53.176326       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:26:23.226940       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:26:23.227001       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:26:53.256003       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:26:53.256041       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:27:23.333227       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:27:23.333275       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:27:53.369807       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:27:53.369858       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:28:23.398819       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:28:23.398872       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:28:53.428625       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:28:53.428660       1 proxier.go:855] "Sync failed" retryingTime="30s"
E0122 18:29:23.464210       1 proxier.go:1504] "Failed to execute iptables-restore" err=<
	exit status 2: ip6tables-restore v1.8.7 (legacy): unknown option "--random-fully"
	Error occurred at line: 18
	Try `ip6tables-restore -h' or 'ip6tables-restore --help' for more information.
 >
I0122 18:29:23.464247       1 proxier.go:855] "Sync failed" retryingTime="30s"

* 
* ==> kube-scheduler [00f18cd045ad] <==
* W0124 16:31:28.066471       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.066582       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: Get "https://192.168.49.2:8443/apis/apps/v1/statefulsets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.196497       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.196569       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.223490       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.223562       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.239684       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.239750       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.248362       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.248445       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.270203       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.270275       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.310970       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.311041       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.343271       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.343362       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: Get "https://192.168.49.2:8443/api/v1/namespaces/kube-system/configmaps?fieldSelector=metadata.name%!D(MISSING)extension-apiserver-authentication&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.435122       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.435192       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.551218       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.551296       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.623134       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.623285       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.623160       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.623326       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.646275       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.646345       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/storageclasses?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:28.743766       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0124 16:31:28.743863       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0124 16:31:34.418746       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0124 16:31:34.418790       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0124 16:31:34.418807       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0124 16:31:34.418803       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0124 16:31:34.418833       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0124 16:31:34.418862       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0124 16:31:34.418745       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0124 16:31:34.418899       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0124 16:31:34.418917       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0124 16:31:34.418956       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0124 16:31:34.418835       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0124 16:31:34.419028       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0124 16:31:34.418743       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0124 16:31:34.419056       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0124 16:31:34.418774       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0124 16:31:34.419091       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0124 16:31:34.419106       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0124 16:31:34.419077       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0124 16:31:34.418821       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0124 16:31:34.418841       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0124 16:31:34.418936       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0124 16:31:34.419161       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0124 16:31:34.418971       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0124 16:31:34.419229       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0124 16:31:34.418988       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0124 16:31:34.419282       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0124 16:31:34.418778       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0124 16:31:34.419292       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
I0124 16:31:34.436078       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0124 16:38:45.147411       1 trace.go:205] Trace[1100965805]: "Scheduling" namespace:ingress-nginx,name:ingress-nginx-admission-create-w4rwl (24-Jan-2023 16:38:45.035) (total time: 111ms):
Trace[1100965805]: ---"Computing predicates done" 111ms (16:38:45.147)
Trace[1100965805]: [111.7766ms] [111.7766ms] END

* 
* ==> kube-scheduler [6f281bf122cb] <==
* E0122 17:28:57.257347       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:57.301346       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:57.301459       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:57.327375       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:57.327525       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:57.422420       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:57.422494       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: Get "https://192.168.49.2:8443/api/v1/nodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:57.426060       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:57.426131       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: Get "https://192.168.49.2:8443/api/v1/namespaces?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:57.426073       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:57.426192       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: Get "https://192.168.49.2:8443/apis/apps/v1/replicasets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:57.467900       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:57.467955       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:58.731231       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:58.731386       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: Get "https://192.168.49.2:8443/api/v1/persistentvolumes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:58.979768       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:58.979906       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: Get "https://192.168.49.2:8443/api/v1/services?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.218441       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.218497       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: Get "https://192.168.49.2:8443/api/v1/pods?fieldSelector=status.phase%3DSucceeded%!C(MISSING)status.phase%3DFailed&limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.359284       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.359463       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csistoragecapacities?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.448037       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.448200       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: Get "https://192.168.49.2:8443/apis/policy/v1/poddisruptionbudgets?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.494023       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.494119       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csinodes?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.540871       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.541093       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: Get "https://192.168.49.2:8443/api/v1/replicationcontrollers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.551980       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.552178       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: Get "https://192.168.49.2:8443/apis/storage.k8s.io/v1/csidrivers?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:28:59.641320       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
E0122 17:28:59.641391       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: Get "https://192.168.49.2:8443/api/v1/persistentvolumeclaims?limit=500&resourceVersion=0": dial tcp 192.168.49.2:8443: connect: connection refused
W0122 17:29:03.576676       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0122 17:29:03.576947       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0122 17:29:03.585579       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0122 17:29:03.585825       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0122 17:29:03.585851       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0122 17:29:03.585882       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0122 17:29:03.585826       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0122 17:29:03.585904       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0122 17:29:03.585692       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0122 17:29:03.585958       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0122 17:29:03.585754       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0122 17:29:03.586030       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0122 17:29:03.585753       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0122 17:29:03.586153       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0122 17:29:03.586204       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0122 17:29:03.586589       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0122 17:29:03.585580       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0122 17:29:03.585792       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0122 17:29:03.586906       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0122 17:29:03.586956       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
I0122 17:29:07.444627       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0122 17:44:03.053625       1 trace.go:205] Trace[1177795270]: "Scheduling" namespace:default,name:posts-depl-577f4d78-nk8jk (22-Jan-2023 17:44:02.636) (total time: 400ms):
Trace[1177795270]: ---"Computing predicates done" 400ms (17:44:03.037)
Trace[1177795270]: [400.7535ms] [400.7535ms] END
I0122 18:29:34.988760       1 configmap_cafile_content.go:223] "Shutting down controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0122 18:29:34.988833       1 tlsconfig.go:255] "Shutting down DynamicServingCertificateController"
I0122 18:29:35.325922       1 secure_serving.go:255] Stopped listening on 127.0.0.1:10259
E0122 18:29:35.332227       1 scheduling_queue.go:963] "Error while retrieving next pod from scheduling queue" err="scheduling queue is closed"
E0122 18:29:35.582973       1 run.go:74] "command failed" err="finished without leader elect"

* 
* ==> kubelet <==
* -- Logs begin at Tue 2023-01-24 16:30:12 UTC, end at Tue 2023-01-24 16:43:51 UTC. --
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.829744    1117 topology_manager.go:205] "Topology Admit Handler"
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.830004    1117 topology_manager.go:205] "Topology Admit Handler"
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.830086    1117 topology_manager.go:205] "Topology Admit Handler"
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.992620    1117 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-25zlk\" (UniqueName: \"kubernetes.io/projected/576b879b-de24-48ae-974e-c9a909de3fdb-kube-api-access-25zlk\") pod \"ingress-nginx-admission-patch-s7qhr\" (UID: \"576b879b-de24-48ae-974e-c9a909de3fdb\") " pod="ingress-nginx/ingress-nginx-admission-patch-s7qhr"
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.992685    1117 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-pd4jd\" (UniqueName: \"kubernetes.io/projected/a0d8e2eb-54c8-48ad-af6e-6d3090b2628f-kube-api-access-pd4jd\") pod \"ingress-nginx-admission-create-w4rwl\" (UID: \"a0d8e2eb-54c8-48ad-af6e-6d3090b2628f\") " pod="ingress-nginx/ingress-nginx-admission-create-w4rwl"
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.992710    1117 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert\") pod \"ingress-nginx-controller-8574b6d7c9-9clxt\" (UID: \"f623a84d-fdb2-48f3-aa1e-ffb9f352c36c\") " pod="ingress-nginx/ingress-nginx-controller-8574b6d7c9-9clxt"
Jan 24 16:38:45 minikube kubelet[1117]: I0124 16:38:45.992731    1117 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-g7jzr\" (UniqueName: \"kubernetes.io/projected/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-kube-api-access-g7jzr\") pod \"ingress-nginx-controller-8574b6d7c9-9clxt\" (UID: \"f623a84d-fdb2-48f3-aa1e-ffb9f352c36c\") " pod="ingress-nginx/ingress-nginx-controller-8574b6d7c9-9clxt"
Jan 24 16:38:46 minikube kubelet[1117]: E0124 16:38:46.217434    1117 secret.go:192] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Jan 24 16:38:46 minikube kubelet[1117]: E0124 16:38:46.217587    1117 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert podName:f623a84d-fdb2-48f3-aa1e-ffb9f352c36c nodeName:}" failed. No retries permitted until 2023-01-24 16:38:46.7175572 +0000 UTC m=+474.189239101 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert") pod "ingress-nginx-controller-8574b6d7c9-9clxt" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c") : secret "ingress-nginx-admission" not found
Jan 24 16:38:46 minikube kubelet[1117]: E0124 16:38:46.815093    1117 secret.go:192] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Jan 24 16:38:46 minikube kubelet[1117]: E0124 16:38:46.815214    1117 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert podName:f623a84d-fdb2-48f3-aa1e-ffb9f352c36c nodeName:}" failed. No retries permitted until 2023-01-24 16:38:47.8151984 +0000 UTC m=+475.286880301 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert") pod "ingress-nginx-controller-8574b6d7c9-9clxt" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c") : secret "ingress-nginx-admission" not found
Jan 24 16:38:47 minikube kubelet[1117]: E0124 16:38:47.823749    1117 secret.go:192] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Jan 24 16:38:47 minikube kubelet[1117]: E0124 16:38:47.823850    1117 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert podName:f623a84d-fdb2-48f3-aa1e-ffb9f352c36c nodeName:}" failed. No retries permitted until 2023-01-24 16:38:49.8238346 +0000 UTC m=+477.295516501 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert") pod "ingress-nginx-controller-8574b6d7c9-9clxt" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c") : secret "ingress-nginx-admission" not found
Jan 24 16:38:48 minikube kubelet[1117]: E0124 16:38:48.456522    1117 kuberuntime_manager.go:1006] "PodSandboxStatus of sandbox for pod" err="rpc error: code = Unknown desc = Error: No such container: f26da7bcfc4024c7d505a26f68a376879960a6ee25d930bb75817516acbf53f6" podSandboxID="f26da7bcfc4024c7d505a26f68a376879960a6ee25d930bb75817516acbf53f6" pod="ingress-nginx/ingress-nginx-admission-create-w4rwl"
Jan 24 16:38:48 minikube kubelet[1117]: E0124 16:38:48.456567    1117 generic.go:411] "PLEG: Write status" err="rpc error: code = Unknown desc = Error: No such container: f26da7bcfc4024c7d505a26f68a376879960a6ee25d930bb75817516acbf53f6" pod="ingress-nginx/ingress-nginx-admission-create-w4rwl"
Jan 24 16:38:48 minikube kubelet[1117]: E0124 16:38:48.458349    1117 kuberuntime_manager.go:1006] "PodSandboxStatus of sandbox for pod" err="rpc error: code = Unknown desc = Error: No such container: fbab387fa2923b60386e473611bd6a7595515053900827e1dcb2d7a05f1589c1" podSandboxID="fbab387fa2923b60386e473611bd6a7595515053900827e1dcb2d7a05f1589c1" pod="ingress-nginx/ingress-nginx-admission-patch-s7qhr"
Jan 24 16:38:48 minikube kubelet[1117]: E0124 16:38:48.458388    1117 generic.go:411] "PLEG: Write status" err="rpc error: code = Unknown desc = Error: No such container: fbab387fa2923b60386e473611bd6a7595515053900827e1dcb2d7a05f1589c1" pod="ingress-nginx/ingress-nginx-admission-patch-s7qhr"
Jan 24 16:38:49 minikube kubelet[1117]: E0124 16:38:49.838833    1117 secret.go:192] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Jan 24 16:38:49 minikube kubelet[1117]: E0124 16:38:49.838940    1117 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert podName:f623a84d-fdb2-48f3-aa1e-ffb9f352c36c nodeName:}" failed. No retries permitted until 2023-01-24 16:38:53.8389242 +0000 UTC m=+481.310606101 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert") pod "ingress-nginx-controller-8574b6d7c9-9clxt" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c") : secret "ingress-nginx-admission" not found
Jan 24 16:38:53 minikube kubelet[1117]: I0124 16:38:53.472745    1117 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="f26da7bcfc4024c7d505a26f68a376879960a6ee25d930bb75817516acbf53f6"
Jan 24 16:38:53 minikube kubelet[1117]: I0124 16:38:53.476244    1117 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="fbab387fa2923b60386e473611bd6a7595515053900827e1dcb2d7a05f1589c1"
Jan 24 16:38:53 minikube kubelet[1117]: E0124 16:38:53.894599    1117 secret.go:192] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Jan 24 16:38:53 minikube kubelet[1117]: E0124 16:38:53.894705    1117 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert podName:f623a84d-fdb2-48f3-aa1e-ffb9f352c36c nodeName:}" failed. No retries permitted until 2023-01-24 16:39:01.8946862 +0000 UTC m=+489.366368101 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert") pod "ingress-nginx-controller-8574b6d7c9-9clxt" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c") : secret "ingress-nginx-admission" not found
Jan 24 16:39:01 minikube kubelet[1117]: E0124 16:39:01.903505    1117 secret.go:192] Couldn't get secret ingress-nginx/ingress-nginx-admission: secret "ingress-nginx-admission" not found
Jan 24 16:39:01 minikube kubelet[1117]: E0124 16:39:01.903608    1117 nestedpendingoperations.go:348] Operation for "{volumeName:kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert podName:f623a84d-fdb2-48f3-aa1e-ffb9f352c36c nodeName:}" failed. No retries permitted until 2023-01-24 16:39:17.9035928 +0000 UTC m=+505.375274701 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "webhook-cert" (UniqueName: "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert") pod "ingress-nginx-controller-8574b6d7c9-9clxt" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c") : secret "ingress-nginx-admission" not found
Jan 24 16:39:04 minikube kubelet[1117]: E0124 16:39:04.699220    1117 remote_runtime.go:599] "ContainerStatus from runtime service failed" err="rpc error: code = Unknown desc = Error: No such container: d4321fd219846b09fb7bf59825d714f37eaac2a5889f364d56ca1e60ede1db90" containerID="d4321fd219846b09fb7bf59825d714f37eaac2a5889f364d56ca1e60ede1db90"
Jan 24 16:39:04 minikube kubelet[1117]: E0124 16:39:04.699273    1117 kuberuntime_manager.go:1024] "getPodContainerStatuses for pod failed" err="rpc error: code = Unknown desc = Error: No such container: d4321fd219846b09fb7bf59825d714f37eaac2a5889f364d56ca1e60ede1db90" pod="ingress-nginx/ingress-nginx-admission-create-w4rwl"
Jan 24 16:39:04 minikube kubelet[1117]: E0124 16:39:04.699285    1117 generic.go:411] "PLEG: Write status" err="rpc error: code = Unknown desc = Error: No such container: d4321fd219846b09fb7bf59825d714f37eaac2a5889f364d56ca1e60ede1db90" pod="ingress-nginx/ingress-nginx-admission-create-w4rwl"
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.173449    1117 reconciler.go:211] "operationExecutor.UnmountVolume started for volume \"kube-api-access-25zlk\" (UniqueName: \"kubernetes.io/projected/576b879b-de24-48ae-974e-c9a909de3fdb-kube-api-access-25zlk\") pod \"576b879b-de24-48ae-974e-c9a909de3fdb\" (UID: \"576b879b-de24-48ae-974e-c9a909de3fdb\") "
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.324908    1117 operation_generator.go:890] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/576b879b-de24-48ae-974e-c9a909de3fdb-kube-api-access-25zlk" (OuterVolumeSpecName: "kube-api-access-25zlk") pod "576b879b-de24-48ae-974e-c9a909de3fdb" (UID: "576b879b-de24-48ae-974e-c9a909de3fdb"). InnerVolumeSpecName "kube-api-access-25zlk". PluginName "kubernetes.io/projected", VolumeGidValue ""
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.338556    1117 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="fbab387fa2923b60386e473611bd6a7595515053900827e1dcb2d7a05f1589c1"
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.376086    1117 reconciler.go:399] "Volume detached for volume \"kube-api-access-25zlk\" (UniqueName: \"kubernetes.io/projected/576b879b-de24-48ae-974e-c9a909de3fdb-kube-api-access-25zlk\") on node \"minikube\" DevicePath \"\""
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.578405    1117 reconciler.go:211] "operationExecutor.UnmountVolume started for volume \"kube-api-access-pd4jd\" (UniqueName: \"kubernetes.io/projected/a0d8e2eb-54c8-48ad-af6e-6d3090b2628f-kube-api-access-pd4jd\") pod \"a0d8e2eb-54c8-48ad-af6e-6d3090b2628f\" (UID: \"a0d8e2eb-54c8-48ad-af6e-6d3090b2628f\") "
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.581632    1117 operation_generator.go:890] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/a0d8e2eb-54c8-48ad-af6e-6d3090b2628f-kube-api-access-pd4jd" (OuterVolumeSpecName: "kube-api-access-pd4jd") pod "a0d8e2eb-54c8-48ad-af6e-6d3090b2628f" (UID: "a0d8e2eb-54c8-48ad-af6e-6d3090b2628f"). InnerVolumeSpecName "kube-api-access-pd4jd". PluginName "kubernetes.io/projected", VolumeGidValue ""
Jan 24 16:39:15 minikube kubelet[1117]: I0124 16:39:15.678945    1117 reconciler.go:399] "Volume detached for volume \"kube-api-access-pd4jd\" (UniqueName: \"kubernetes.io/projected/a0d8e2eb-54c8-48ad-af6e-6d3090b2628f-kube-api-access-pd4jd\") on node \"minikube\" DevicePath \"\""
Jan 24 16:39:16 minikube kubelet[1117]: I0124 16:39:16.354321    1117 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="f26da7bcfc4024c7d505a26f68a376879960a6ee25d930bb75817516acbf53f6"
Jan 24 16:39:20 minikube kubelet[1117]: E0124 16:39:20.396377    1117 kuberuntime_manager.go:1006] "PodSandboxStatus of sandbox for pod" err="rpc error: code = Unknown desc = Error: No such container: 3f2986ed5539a97bfd229d2efc49dd32450ddef37affe257d76fdc22cc1df8d5" podSandboxID="3f2986ed5539a97bfd229d2efc49dd32450ddef37affe257d76fdc22cc1df8d5" pod="ingress-nginx/ingress-nginx-controller-8574b6d7c9-9clxt"
Jan 24 16:39:20 minikube kubelet[1117]: E0124 16:39:20.396423    1117 generic.go:411] "PLEG: Write status" err="rpc error: code = Unknown desc = Error: No such container: 3f2986ed5539a97bfd229d2efc49dd32450ddef37affe257d76fdc22cc1df8d5" pod="ingress-nginx/ingress-nginx-controller-8574b6d7c9-9clxt"
Jan 24 16:39:21 minikube kubelet[1117]: I0124 16:39:21.416863    1117 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="3f2986ed5539a97bfd229d2efc49dd32450ddef37affe257d76fdc22cc1df8d5"
Jan 24 16:39:29 minikube kubelet[1117]: I0124 16:39:29.039019    1117 topology_manager.go:205] "Topology Admit Handler"
Jan 24 16:39:29 minikube kubelet[1117]: E0124 16:39:29.293060    1117 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="576b879b-de24-48ae-974e-c9a909de3fdb" containerName="patch"
Jan 24 16:39:29 minikube kubelet[1117]: E0124 16:39:29.293120    1117 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="a0d8e2eb-54c8-48ad-af6e-6d3090b2628f" containerName="create"
Jan 24 16:39:29 minikube kubelet[1117]: I0124 16:39:29.293184    1117 memory_manager.go:345] "RemoveStaleState removing state" podUID="a0d8e2eb-54c8-48ad-af6e-6d3090b2628f" containerName="create"
Jan 24 16:39:29 minikube kubelet[1117]: I0124 16:39:29.293191    1117 memory_manager.go:345] "RemoveStaleState removing state" podUID="576b879b-de24-48ae-974e-c9a909de3fdb" containerName="patch"
Jan 24 16:39:29 minikube kubelet[1117]: I0124 16:39:29.429461    1117 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/094b7013-64b4-4ab2-b77f-edf5232f1244-webhook-cert\") pod \"ingress-nginx-controller-5959f988fd-sr6q9\" (UID: \"094b7013-64b4-4ab2-b77f-edf5232f1244\") " pod="ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9"
Jan 24 16:39:29 minikube kubelet[1117]: I0124 16:39:29.429537    1117 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-m7hql\" (UniqueName: \"kubernetes.io/projected/094b7013-64b4-4ab2-b77f-edf5232f1244-kube-api-access-m7hql\") pod \"ingress-nginx-controller-5959f988fd-sr6q9\" (UID: \"094b7013-64b4-4ab2-b77f-edf5232f1244\") " pod="ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9"
Jan 24 16:39:35 minikube kubelet[1117]: E0124 16:39:35.618231    1117 kuberuntime_manager.go:1006] "PodSandboxStatus of sandbox for pod" err="rpc error: code = Unknown desc = Error: No such container: b73466abfafa7ad5a24a662aa08ff661613a333a5e149172327563a0e24cce75" podSandboxID="b73466abfafa7ad5a24a662aa08ff661613a333a5e149172327563a0e24cce75" pod="ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9"
Jan 24 16:39:35 minikube kubelet[1117]: E0124 16:39:35.618272    1117 generic.go:411] "PLEG: Write status" err="rpc error: code = Unknown desc = Error: No such container: b73466abfafa7ad5a24a662aa08ff661613a333a5e149172327563a0e24cce75" pod="ingress-nginx/ingress-nginx-controller-5959f988fd-sr6q9"
Jan 24 16:39:36 minikube kubelet[1117]: I0124 16:39:36.694793    1117 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="b73466abfafa7ad5a24a662aa08ff661613a333a5e149172327563a0e24cce75"
Jan 24 16:40:33 minikube kubelet[1117]: I0124 16:40:33.687047    1117 reconciler.go:211] "operationExecutor.UnmountVolume started for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert\") pod \"f623a84d-fdb2-48f3-aa1e-ffb9f352c36c\" (UID: \"f623a84d-fdb2-48f3-aa1e-ffb9f352c36c\") "
Jan 24 16:40:33 minikube kubelet[1117]: I0124 16:40:33.687163    1117 reconciler.go:211] "operationExecutor.UnmountVolume started for volume \"kube-api-access-g7jzr\" (UniqueName: \"kubernetes.io/projected/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-kube-api-access-g7jzr\") pod \"f623a84d-fdb2-48f3-aa1e-ffb9f352c36c\" (UID: \"f623a84d-fdb2-48f3-aa1e-ffb9f352c36c\") "
Jan 24 16:40:33 minikube kubelet[1117]: I0124 16:40:33.716621    1117 operation_generator.go:890] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-kube-api-access-g7jzr" (OuterVolumeSpecName: "kube-api-access-g7jzr") pod "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c"). InnerVolumeSpecName "kube-api-access-g7jzr". PluginName "kubernetes.io/projected", VolumeGidValue ""
Jan 24 16:40:33 minikube kubelet[1117]: I0124 16:40:33.727246    1117 operation_generator.go:890] UnmountVolume.TearDown succeeded for volume "kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert" (OuterVolumeSpecName: "webhook-cert") pod "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c" (UID: "f623a84d-fdb2-48f3-aa1e-ffb9f352c36c"). InnerVolumeSpecName "webhook-cert". PluginName "kubernetes.io/secret", VolumeGidValue ""
Jan 24 16:40:33 minikube kubelet[1117]: I0124 16:40:33.787377    1117 reconciler.go:399] "Volume detached for volume \"webhook-cert\" (UniqueName: \"kubernetes.io/secret/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-webhook-cert\") on node \"minikube\" DevicePath \"\""
Jan 24 16:40:33 minikube kubelet[1117]: I0124 16:40:33.787416    1117 reconciler.go:399] "Volume detached for volume \"kube-api-access-g7jzr\" (UniqueName: \"kubernetes.io/projected/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c-kube-api-access-g7jzr\") on node \"minikube\" DevicePath \"\""
Jan 24 16:40:34 minikube kubelet[1117]: I0124 16:40:34.587950    1117 scope.go:115] "RemoveContainer" containerID="890ab108e1a11d43086a93fe127311d8cdf0c8fbb37708a2449a0ba4cca461c6"
Jan 24 16:40:36 minikube kubelet[1117]: I0124 16:40:36.195578    1117 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f623a84d-fdb2-48f3-aa1e-ffb9f352c36c path="/var/lib/kubelet/pods/f623a84d-fdb2-48f3-aa1e-ffb9f352c36c/volumes"
Jan 24 16:40:56 minikube kubelet[1117]: W0124 16:40:56.037446    1117 sysinfo.go:203] Nodes topology is not available, providing CPU topology
Jan 24 16:40:56 minikube kubelet[1117]: I0124 16:40:56.142671    1117 container_manager_linux.go:849] "CPUAccounting not enabled for process" pid=1117
Jan 24 16:40:56 minikube kubelet[1117]: I0124 16:40:56.142714    1117 container_manager_linux.go:852] "MemoryAccounting not enabled for process" pid=1117

* 
* ==> storage-provisioner [3a4e0263cf31] <==
* I0124 16:32:29.393012       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
F0124 16:32:59.970699       1 main.go:39] error getting server version: Get "https://10.96.0.1:443/version?timeout=32s": dial tcp 10.96.0.1:443: i/o timeout

* 
* ==> storage-provisioner [c5eb05ca2839] <==
* I0124 16:33:28.025919       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0124 16:33:28.431064       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0124 16:33:28.431642       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0124 16:33:45.848594       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0124 16:33:45.848737       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"1a108e17-73aa-4d15-9514-720000cf2094", APIVersion:"v1", ResourceVersion:"15988", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_57956ea0-3f11-4b0b-876a-ece4758c148e became leader
I0124 16:33:45.848826       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_57956ea0-3f11-4b0b-876a-ece4758c148e!
I0124 16:33:45.949126       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_57956ea0-3f11-4b0b-876a-ece4758c148e!

